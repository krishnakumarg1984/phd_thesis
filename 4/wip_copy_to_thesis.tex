\subsection{Candidate Schemes for Block-Hankel \gls{svd}}

\begin{figure*}
	\caption{}
	\label{improved_ROM_workflow}
\end{figure*}

Generic \gls{svd} routines such as DGE\gls{svd} do not take advantage of the anti-diagonal
structural symmetry of Block-Hankel matrices. Since it is sufficient
to obtain the first few leading eigentriplets for order reduction,
iterative algorithms such as the Jacobi and Lanczos schemes described
in~\cite{GolubVanLoan2012} emerge as attractive candidates for
computing these dominant singular values and vectors. In order to
ensure accessibility to the large community of battery researchers
and encourage widespread adoption of the fast reduced order modelling,
we consider only freely available open-source numerical libraries
in the public domain with permissive licensing terms. Otherwise the
gains achieved by efficient \gls{svd} computation for implementing \gls{dra}on
non-specialized computing hardware would be offset by commercial licensing
terms, usage restrictions and monetary considerations associated with
using proprietary codes. Among these open-source candidate algorithms,
the Jacobi scheme~\cite{GolubVanLoan2012} is available through
the xGE\gls{svd} routine in the LAPACK suite. FORTRAN 77 codes for the implicitly
restarted Arnoldi and Lanczos schemes (nuTrLan) are made available
as part of the ARPACK~\cite{LehoucqMaschhoffSorensenEtAl2013} libraries.

The practical drawback of most \gls{svd} implementations, both open-source
and proprietary, is that they require the entire matrix as input argument.
Since operating upon the Block-Hankel matrix requires constructing
it in the first place, the memory bottlenecks discussed in Section~\ref{subsec:Traditional-DRA--Memory}
are not ameliorated. An example is the \texttt{svds} routine, an economy
size \gls{svd} implementation in MATLAB. Albeit a commercial implementation
of the Arnoldi codes, potential benefits of using an iterative scheme
is nullified by the memory penalty. Owing to reasons enumerated in
Section \ref{sec:Efficient-Computation-of}, the chosen \gls{svd} algorithm
needs to be able to handle the computation without actually forming
the huge block-Hankel matrix in memory.

\subsection{\gls{svd} Operation on a Virtual Block-Hankel Matrix}

R.M. Larsen's pioneering work PROPACK~\cite{Larsen2014} implements
a numerically stable Lanczos \gls{svd} computation designed specifically
for large and sparse matrices. In addition to the ability to operate
on the matrix as a whole, the PROPACK codes possess a unique flexibility
of accepting input arguments in functional form. A key highlight of
the Lanczos \gls{svd} scheme is that it does not strictly require the matrix
itself, but only the product of the matrix and its transpose with
an arbitrary vector. This feature has been effectively exploited in
the PROPACK suite. Therefore, these multiplication routines can be
supplied as input arguments instead of forming the large Block-Hankel
matrices in memory. Furthermore, this package includes sophisticated
schemes such as Gram-Schmidt partial re-orthogonalization~\cite{Bjoerck1994}
to compensate for numerical round-off errors in the basic Lanczos
bidiagonalization and ensures orthogonality of the input and output
singular vectors. The PROPACK suite is available as both Fortran 77
and MATLAB codes distributed under a permissive BSD license~\cite{Rosen2005}.

For the \gls{rom} workflow, in order to use PROPACK's unique feature, i.e.
its flexibility to accept functional form inputs, the key is to use
an algorithm that effectively exploits the affine structure of the
Block-Hankel matrix without actually forming it in memory. Recent
research in a specialized time-series technique known as Singular
Spectrum Analysis (SSA)~\cite{ElsnerTsonis2013} has yielded efficient
methods for achieving this goal. Korobeynikov~\cite{Korobeynikov2009}
proposed an algorithm that employs the Fast Fourier Transform (FFT)
for implementing this matrix-vector product by embedding the Markov
parameters into the column vectors of a circulant matrix. This is
suitable for applications wherein the Hankel matrix is composed of
scalar entries such as that formed by the Markov parameters of a single
input single output (SISO) transfer function. Golyandina and Usevich~\cite{GolyandinaKorobeynikovShlemovEtAl2015,GolyandinaUsevich2004}
extended this approach to a generic 2D-case for performing Singular
Spectrum Analysis (SSA) on images. With this modification, this algorithm
is rendered capable of handling the structure of Multi-level Block-Hankel
matrices formed from the Markov parameters of a generic Multi-Input-Multi-Output
(MIMO) system. While the modified scheme does not construct the Block-Hankel
matrix in memory, the operational rubrics of the Golyandina-Usevich
algorithm in conjunction with PROPACK is such that they iteratively
operate on a virtual Hankel matrix of equivalent size. The Golyandina-Usevich
algorithm is briefly summarized in Appendix \ref{sec:Golyandina-Usevich-Algorithm}.

\subsection{Customizations for Battery modelling}

Specific considerations are required for incorporating the Golyandina-Usevich
algorithm in the \gls{rom} workflow for Li-ion batteries. The classical
\gls{dra}architecture is set up to handle Single Input Multiple Output
(SIMO) systems, wherein all transfer functions are derived by considering
only a single input \textendash{} the applied battery current. Thus
the Markov parameters form a 2D matrix wherein each row corresponds
to individual battery transfer functions with columns representing
unit-pulse response samples for each transfer function. The 2D moving-window
illustrated in \cite{GolyandinaKorobeynikovShlemovEtAl2015} for
Block-Hankel matrix formulation has to be suitably reshaped to account
for this structure. Step-3 of the algorithm deals with 2-D FFT computation
of the Markov Parameter Matrix (MPM). In our implementation, this
is pre-computed as it remains invariant between iterations of the
Hankel-vector product computation loop. This pre-allocation and a
priori computation contributes to overall code efficiency.

Figure~\ref{improved_ROM_workflow} shows the \gls{rom} workflow with
the improved \gls{dra}wherein all computational bottlenecks highlighted
by shaded blocks in Figure~\ref{traditional_ROM_Workflow} have
been eliminated. The strategy is to first employ the (suitably modified)
Golyandina-Usevich algorithm for describing the matrix-vector multiplication
routines. These two functions are then used as inputs to the PROPACK
codes. Eigentriplets up to the desired upper bound on system order
is then computed using a Lanczos \gls{svd} iteration. Figure~\ref{svdcompare}
presents a comparison of singular values computed by both the  traditional
and new methodologies. It is evident that the two sets of singular
values are identical. Hence, this new scheme can serve as a drop-in
replacement for the classical \gls{dra}.

\begin{figure}
	\caption{}
	\label{svdcompare}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Simulation Results and Discussion\label{sec:Results} }

In this section, we quantitatively demonstrate the reduced computational
demand of the improved \gls{dra}scheme by comparing it against the classical
\gls{dra}implementation. The physical parameters of the cell are the same
as those published in Doyle et al.\cite{FullerDoyleNewman1994}.
Table~\ref{table:simparams} lists the parameters used in the ROM
workflow, which are the same as those employed by Lee~et~al.\cite{LeeChemistruckPlett2012}.

\begin{figure}
	\caption{}
	\label{memory}
\end{figure}

Figure~\ref{memory} shows a comparison of the memory usage of
classical and improved \gls{dra}methods. It is evident that the \gls{svd} step
in classical \gls{dra}consumes an overwhelming majority of the total memory
demand, requiring approximately 100 GB for a Hankel block size of
8000. This can be a limiting factor in modelling slow cell dynamics
without access to a large memory workstation. The improved \gls{dra}method
eliminates this bottleneck and the memory usage of \gls{svd} step is trivial.
Overall memory usage of the improved \gls{dra}is dominated by Markov parameter
computation. Considering 10 GB of usable \gls{ram}, 60000 Markov parameters
(Hankel Block-size of 30000) can be captured.

Figure~\ref{cputime} shows a comparison of \gls{cpu} times for computing
the \gls{rom} at a single \gls{soc} and temperature for the classical and improved
\gls{dra}methods. Appendix \ref{sec:Specifications-of-Workstation} lists the specifications
of the workstation used for the computations. Owing to the high flop
count for \gls{svd} operation (eq.~\ref{eq:cpu_op_count}), the classical
\gls{dra}requires approximately 40 minutes for a Hankel block size of 8000.
Clearly, the overall \gls{cpu} time for classical \gls{dra}is almost exclusively
used in computing the \gls{svd}. The improved \gls{dra}method reduces the overall
computational time by two orders of magnitude, taking approximately
40 seconds for the same block-size. In this case, \gls{cpu} time is evenly
split between \gls{svd} and Markov parameters computations.

\begin{figure}
	\caption{}
	\label{cputime}
\end{figure}

From Figure~\ref{memory}, it is evident that if classical \gls{dra}
is employed, a standard laptop with a nominal 10 GB \gls{ram} limit (dedicated
for \gls{rom} workflow) cannot capture the full cell dynamics and hence
is restricted to 2500 Hankel blocks. This necessitates early truncation
of Markov parameters at 5000 seconds. From Figure~\ref{markov_cse_pos},
the truncation residue at 5000 seconds for the unit-pulse response
of solid surface concentration at positive current collector is $-0.0087 \text{ mol m}^{-\text{3}}$.
The truncation errors in the Markov Parameter Matrix directly translate
to errors in computed singular values, adversely affecting accuracy
of simulated cell variables. It must be noted that the accuracy of
simulation results reported here does not bear a causal relationship
to the particular \gls{dra}scheme employed. In-principle, when an upper
bound on computational usage has not been enforced, the numerical
operations of both the existing and proposed \gls{dra}schemes lead to similar
error magnitudes for the modelled quantities. Instead, the accuracy
comparison illustrated here primarily serves to demonstrate the practical
usefulness of the improved \gls{dra}scheme when implemented in a commonplace
computing environment.

\begin{figure}
	\caption{}
	\label{truncated}
\end{figure}

Figure~\ref{truncated} shows a comparison of singular values obtained
by the classical and improved \gls{svd} methods computed by imposing a \gls{ram}
limit of 10GB. Owing to early truncation of the Markov parameter matrix,
the dominant singular values computed by the conventional method differ
significantly from those computed by the improved \gls{svd} operating on
untruncated data. With the same memory constraints, the improved \gls{dra}
can handle up to 30000 Hankel blocks, allowing for capture of 60000
seconds of Markov parameter data.

For comparative analysis of modelling accuracy under this memory constraint,
a time-domain simulation of the ROMs obtained by classical and improved
\gls{dra}methods is performed. The input current profile corresponding
to UDDS drive cycle reported in Lee~et~al. \cite{LeeChemistruckPlett2012}
is used. Figure~\ref{time_domain_sim} depicts the time-evolution
of the solid surface concentration at the positive electrode/separator
boundary. For comparing the accuracy of the two ROMs, a COMSOL Multiphysics~\cite{Multiphysics2012}
simulation of the full-order pseudo-2D porous-electrode PDE model
is used as the reference. The \gls{rom} employing classical \gls{dra}diverges
over time, and after 1500 seconds results in an error of 1120$\text{ mol m}^{-\text{3}}$$.$
The \gls{rom} incorporating the new \gls{dra}workflow accurately tracks the COMSOL
simulation trend-line. Table~\ref{table:salientresults} provides
a summary of the key simulation results.

\begin{figure}
	\caption{}
	\label{time_domain_sim}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions\label{sec:Conclusion}}
In this paper, Singular Value Decomposition of a large Block-Hankel
matrix is identified as a key bottleneck in the classical \gls{dra}for
reduced-order Li-ion cell modelling. An improved \gls{svd} scheme is presented,
which employs a combination of the Golyandina-Usevich and Lanczos
algorithms. The results discussed in Section \ref{sec:Results} demonstrate
the performance improvement achieved by the new method without trading-off
model fidelity. At a single operating point of \gls{soc} and temperature,
for a Hankel block size of 8000, \gls{rom} workflow incorporating the improved
\gls{dra}is approximately 100 times faster than that employing classical
DRA. Using the machine specifications in Appenndix  \ref{sec:Specifications-of-Workstation},
for 100 operating points (combinations of 10 \gls{soc} and temperature values),
computing the \gls{rom} requires only 6 hours using the improved \gls{dra}, whereas
the classical \gls{dra}consumes 666 hours (27 days). Furthermore, for the
same block-size, the improved \gls{dra}is demonstrated to be superior in
terms of memory efficiency, drastically reducing the memory requirement
from 112 GB down to 2 GB. Finally, the improved \gls{dra}demonstrates superior
modelling accuracy when implemented even in moderately equipped computing
environments such as laptops.

The proposed method leads to the possibility of modelling other physical
quantities in the cell geometry unhindered by computing limitations.
Furthermore, high sample-rate models to handle highly dynamic load
profiles can be deployed in future BMS applications. The scheme also
empowers the \gls{rom} framework to tackle cells with slower dynamics and
other chemistries with different rate-limiting mechanisms. The improved
\gls{dra}method opens up a wide range of possibilities and brings the goal
of physics-based battery model implementation in a high performance
real-time BMS a step closer to realization.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{acknowledgment}
Financial support for the research reported in this paper has been
obtained through the Imperial College President's PhD Scholarships
scheme. The sponsor had no role whatsoever in collection, analysis
and interpretation of data, or in writing of the manuscript. Furthermore,
the funding body has no role/involvement in the decision to submit
the article for publication. The authors wish to acknowledge the support
of The Department of Mathematics, Imperial College London for usage
of the departmental computing cluster. The \gls{cpu} times, memory usage
and all other computational results reported in this paper were obtained
by using a computing node from this facility.
\end{acknowledgment}

\begin{nomenclature}
	\entry{$c_e \scriptstyle(x,t)$}{Concentration of Li$^\text{+}$ ions in the electrolyte at each spatial location within the 1-D cell geometry $(\text{mol m}^{-\text{3}})$}
	\entry{$c_{s,e} \scriptstyle(z,t) $}{Concentration of Li at the surface of each solid particle within the normalized domain length of each electrode $(\text{mol m}^{-\text{3}})$}
	\entry{$\medmuskip=0mu \tilde{c}_{\scriptscriptstyle s,e_{pos}}^*\scriptstyle(0,t) $}{Surface concentration of Li in the solid particle adjacent to positive current collector, obtained after model linearisation and subsequent removal of the integrator pole. The algorithms discussed in this paper require that all model variables have poles located strictly within the open left-half complex plane. Since the solid diffusion transfer functions have poles at the origin, it is necessary to remove this integrator pole before deriving the model $(\text{mol m}^{-\text{3}})$}
	\entry{$L_{neg}$}{Thickness of the negative electrode $(\text{m})$}
	\entry{$L_{sep}$}{Thickness of the separator domain $(\text{m})$}
	\entry{$L_{pos}$}{Thickness of the positive electrode $(\text{m})$}
	\entry{$j \scriptstyle(z,t) $}{Li molar flux density at electrode-electrolye interface of each particle within the normalized electrode domain $(\text{mol m}^{-\text{2}}s^{-\text{1}})$}
	\entry{$\phi_e \scriptstyle(x,t) $}{Electrolyte potential at each spatial location within the 1-D cell geometry $(\text{V})$}
	\entry{$\phi_{s,e} \scriptstyle(z,t) $}{Solid-electrolyte potential difference at the inteerfacial boundary for each spatial location within the 1-D cell geometry $(\text{V})$}
\end{nomenclature}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{asmems4}
\bibliography{\gls{svd}_paper_Bibliography}
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix %%% starting appendix
\section{Golyandina-Usevich Algorithm\label{sec:Golyandina-Usevich-Algorithm}}

The Golyandina-Usevich algorithm is used for computing the product
of a Block-Hankel matrix with an arbitrary vector. The steps involved
in this scheme are enumerated in Algorithm 3 of \cite{GolyandinaKorobeynikovShlemovEtAl2015}.
These steps are reproduced here in the context of discrete-time realization
algorithm for reduced order battery modelling.
\begin{enumerate}
	\item Compute a 2-D FFT of Markov parameter matrix.
	\item Form an augmented vector by zero-padding the arbitrary vector input
	from Lanczos iteration.
	\item Perform a column-wise reshaping of this augmented vector to obtain
	a new matrix with the same dimensions of the Markov parameter matrix.
	\item Compute the element-wise product of this newly created matrix with
	the 2-D FFT of Markov parameter matrix.
	\item Reshape the resulting matrix back to a column vector.
	\item Extract the first $L$ elements from this vector, wherein $L=Kx$.
	$K$ represents the desired block-Hankel size and $x$ represents
	the number of transfer functions being modelled.
\end{enumerate}
At the end of Step 6, the product of the Hankel matrix and arbitrary
vector is obtained. This is reused as an input for the Lanczos scheme
which generates a new arbitrary vector in the subsequent iteration.
Thus, the steps 1\textendash 6 are run in a loop within the main Lanczos
scheme. These same steps can also be used for computing the product
of the transpose of the Hankel matrix and the arbitrary vector. The
only change is to account for the different dimensions of the arbitrary
vector input from the Lanczos scheme in step 2. As a practical implementation,
software code representing steps 1\textendash 6 is written in a plain-text
file and used as functional-form inputs by the PROPACK scheme which
implements the Lanczos iteration.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\singlespacing
\section{Specifications of Workstation Used\label{sec:Specifications-of-Workstation}}

\newpage
\section*{Listing of Table Captions}

\begin{description}
	\item[Table 1]   Parameters for \gls{rom} Computation\\
	\item[Table 2]   Salient Results - Classical vs. Improved \gls{dra}\\
	\item[Table 3]   Specifications of workstation used
\end{description}
\newpage
\section*{Listing of Figure Captions}

\begin{description}
	\item[Fig. 1.]   Reduced-order modelling (ROM) workflow using classical \gls{dra}.\\ (The shaded blocks represent computational bottlenecks).\\
	\item[Fig. 2.]   Time evolution of Markov parameters of pole-removed transfer function corresponding to surface concentration of Li in the solid particle adjacent to positive current collector.\\
	\item[Fig. 3.]   Reduced Order Modelling (ROM) Workflow using improved \gls{dra}.\\
	\item[Fig. 4.]   Comparison of singular values computed by the conventional and improved \gls{svd} methods.\\
	\item[Fig. 5.]	 Memory usage of classical and improved \gls{dra}. Overall \gls{ram} usage as well as \gls{ram} used only for \gls{svd} computation is illustrated.\\
	\item[Fig. 6.] 	 Computation times for classical and improved \gls{dra}schemes.\\
	\item[Fig. 7.]	 Comparison of singular values computed by conventional and improved \gls{svd} methods under a practical \gls{ram} limit of 10 GB.\\
	\item[Fig. 8.]	 Time-domain simulation depicting solid surface concentrations at the boundary of positive electrode and separator.\\
\end{description}

\newpage
\singlespacing
\begin{table}[h]
	\begin{center}
		\caption{Parameters for \gls{rom} Computation}
		\label{table:simparams}
		\begin{tabular}{ l l }
			\hline
			Initial Cell \gls{soc} & 60 \%  \\
			Hankel Block Size & 8000 \\
			Discrete-Time Model Sample-Rate,$T_s$ & 1 sec  \\
			Number of Electrolyte EigenModes & 5 \\
			Continuous-Time Emulation Frequency, $F_1$ & 128 Hz \\
			Desired Number of Singular Values &	10 \\
			\hline
		\end{tabular}
	\end{center}
\end{table}

\newpage
\singlespacing

\begin{table}[h]
	\singlespacing
	\centering
	\caption{Salient Results - Classical vs. Improved \gls{dra}}
	\label{table:salientresults}
	\setlength{\extrarowheight}{1pt}
	%\centering
	\begin{tabular}{ c c c c }
		\hline
		\gls{rom} & Quantity 		& Classical & Improved \\
		Condition		   &				  & \gls{dra}		 & \gls{dra}	  \\
		\hline
		\multirow{8}{1.22cm}{8000 Hankel Blocks}& Memory 		  & 111.80 GB	  & 2.14 GB  \\[-5pt]
		& \footnotesize (overall)		&			 & 		 \\
		& Memory 		  & 97.93 GB	  & 0.03 GB  \\[-5pt]
		& \footnotesize(\gls{svd} step)   	&			 & 		 \\
		& \gls{cpu} Time 		& 39.78 min   & 0.63 min  \\[-5pt]
		& \footnotesize(overall)    	&			 & 		 \\
		& \gls{cpu} Time 		& 39.30 min   & 0.14 min  \\[-5pt]
		& \footnotesize(\gls{svd} step)   	&			 & 		 \\[2.5pt]
		\hline
		\multirow{3}{1.22cm}{10 GB Memory Limit}& Block Size		  & 2500	  & 30000  \\[5pt]
		& Max. error & 1120\scriptsize $\text{ mol m}^{-\text{3}}$ &  13\scriptsize $\text{ mol m}^{-\text{3}}$ \\[-5pt]
		& in $c_{{s,e}_{pos}}$\scriptsize $(1,t)$ &  &     \\[5pt]
		\hline
	\end{tabular}
\end{table}
\newpage
\begin{table}[h]
	\caption{Specifications of workstation used}
	\label{table:comp_spec}
	\centering
	\begin{tabular}{ l l }
		\hline
		Processor & Intel\textregistered\space  Xeon \textregistered\space E5-2637 v3 \\
		Used Cores & 1 \\
		\gls{cpu} Stepping & 2 \\
		Clock Frequency & 3.50 GHz \\
		Installed \gls{ram} & 500 GB \\
		\hline
	\end{tabular}
\end{table}


% achieve the latent  potential and wide applicability  of the
% physics-based reduced order Li-ion battery model.

