\subsection{Summary Effect of Computational Bottlenecks\label{subsec:Summary-Effect-of}}

The computational bottleneck in a classical DRA implementation arises
due to the requirement of capturing a large number of Markov parameters,
which in turn leads to growth in Block-Hankel size. In the case of
battery modeling, this can arise in the following real-life scenarios:
\begin{enumerate}
	\item Electrochemical variables at additional locations of interest within
	the cell (e.g. middle of electrode or separator domain) might need
	to be modeled. This increases the number of transfer functions and
	hence the number of Markov parameters.
	\item High frequency load cycles necessitate higher sample-rates to obtain
	a high fidelity model. This leads to a correspondingly higher number
	of Markov parameters.
	\item In cells with large particle sizes and small diffusion coefficients,
	a large set of Markov parameters is needed to capture the full system
	dynamics.
\end{enumerate}
Lack of specialized computing infrastructure necessitates early truncation
of the Markov parameters in the ROM workflow. The resulting errors
in the singular value computation lead to significant modeling errors
in the physical variables of the cell. Thus, in practice, the computational
bottlenecks of classical DRA manifest as modeling errors when implemented
in a resource-constrained computing environment. Furthermore, this
tedious computation has to be repeated for multiple SoC and temperatures.

The foregoing analysis clearly demonstrates that the high memory and
CPU demands in a classical DRA implementation severely hamper the
scope and applicability of the reduced order modeling process. This
implies that the modeling workflow is not accessible to research groups
without specialized computing infrastructure and its universal appeal
is rendered questionable. The shaded blocks in Figure~\ref{traditional_ROM_Workflow}
depict the hierarchical propagation of the classical DRA's computational
bottleneck throughout the ROM workflow.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Improved DRA for Battery Modeling \label{sec:Efficient-Computation-of}}

Collecting a large Markov parameter set is inevitable due to the fundamental
physics of the cell dynamics as established in Section~\ref{subsec:Summary-Effect-of}.
Hence, in order to circumvent the high computational demands of the
classical DRA, the second step in the process, i.e. forming the Block-Hankel
matrix, is critically examined with the following scientific rationale.
\begin{enumerate}
	\item The unit-pulse responses of most battery transfer functions (other
	than those of rate-limiting steps such as solid diffusion) decay relatively
	quickly. Hence it is inefficient to record the Markov parameters of
	the full system for the entire duration needed to capture the slowest
	dynamics.
	\item The Block-Hankel matrix is essentially redundant information since
	its entries are simply the Markov parameters arranged in a repeating
	special structure. Thus, it is wasteful to construct this huge matrix.
	If the SVD operation can be performed on a virtual Hankel matrix,
	the memory requirements can be drastically reduced.
	\item The matrix of singular values~$\left(\Sigma\right)$ is diagonal
	and hence, sparse. It is redundant to hold all the non-diagonal entries
	(zeros) in memory.
	\item It is not necessary to perform a \textit{full} SVD operation in order
	to achieve order reduction. When an upper bound on desired system
	order can be decided a priori, it is sufficient to compute a \textit{truncated}
	SVD yielding the first few dominant triplets of $U,\text{ \ensuremath{\Sigma}\ \text{and }}V$.
\end{enumerate}
Thus, forming the large Block-Hankel matrix and computing its SVD
is identified as an avoidable bottleneck in the classical DRA method.
This can be tackled since forming the Block-Hankel matrix is an idiosyncrasy
of the algorithm used and does not arise from any fundamental physical
limits. Facilitated by an efficient SVD implementation, we propose
an improved DRA that serves as a drop-in replacement in the ROM workflow.

\subsection{Candidate Schemes for Block-Hankel SVD}

\begin{figure*}
	\caption{}
	\label{improved_ROM_workflow}
\end{figure*}

Generic SVD routines such as DGESVD do not take advantage of the anti-diagonal
structural symmetry of Block-Hankel matrices. Since it is sufficient
to obtain the first few leading eigentriplets for order reduction,
iterative algorithms such as the Jacobi and Lanczos schemes described
in~\citep{GolubVanLoan2012} emerge as attractive candidates for
computing these dominant singular values and vectors. In order to
ensure accessibility to the large community of battery researchers
and encourage widespread adoption of the fast reduced order modeling,
we consider only freely available open-source numerical libraries
in the public domain with permissive licensing terms. Otherwise the
gains achieved by efficient SVD computation for implementing DRA on
non-specialized computing hardware would be offset by commercial licensing
terms, usage restrictions and monetary considerations associated with
using proprietary codes. Among these open-source candidate algorithms,
the Jacobi scheme~\citep{GolubVanLoan2012} is available through
the xGESVD routine in the LAPACK suite. FORTRAN 77 codes for the implicitly
restarted Arnoldi and Lanczos schemes (nuTrLan) are made available
as part of the ARPACK~\citep{LehoucqMaschhoffSorensenEtAl2013} libraries.

The practical drawback of most SVD implementations, both open-source
and proprietary, is that they require the entire matrix as input argument.
Since operating upon the Block-Hankel matrix requires constructing
it in the first place, the memory bottlenecks discussed in Section~\ref{subsec:Traditional-DRA--Memory}
are not ameliorated. An example is the \texttt{svds} routine, an economy
size SVD implementation in MATLAB. Albeit a commercial implementation
of the Arnoldi codes, potential benefits of using an iterative scheme
is nullified by the memory penalty. Owing to reasons enumerated in
Section \ref{sec:Efficient-Computation-of}, the chosen SVD algorithm
needs to be able to handle the computation without actually forming
the huge block-Hankel matrix in memory.

\subsection{SVD Operation on a Virtual Block-Hankel Matrix}

R.M. Larsen's pioneering work PROPACK~\citep{Larsen2014} implements
a numerically stable Lanczos SVD computation designed specifically
for large and sparse matrices. In addition to the ability to operate
on the matrix as a whole, the PROPACK codes possess a unique flexibility
of accepting input arguments in functional form. A key highlight of
the Lanczos SVD scheme is that it does not strictly require the matrix
itself, but only the product of the matrix and its transpose with
an arbitrary vector. This feature has been effectively exploited in
the PROPACK suite. Therefore, these multiplication routines can be
supplied as input arguments instead of forming the large Block-Hankel
matrices in memory. Furthermore, this package includes sophisticated
schemes such as Gram-Schmidt partial re-orthogonalization~\citep{Bjoerck1994}
to compensate for numerical round-off errors in the basic Lanczos
bidiagonalization and ensures orthogonality of the input and output
singular vectors. The PROPACK suite is available as both Fortran 77
and MATLAB codes distributed under a permissive BSD license~\citep{Rosen2005}.

For the ROM workflow, in order to use PROPACK's unique feature, i.e.
its flexibility to accept functional form inputs, the key is to use
an algorithm that effectively exploits the affine structure of the
Block-Hankel matrix without actually forming it in memory. Recent
research in a specialized time-series technique known as Singular
Spectrum Analysis (SSA)~\citep{ElsnerTsonis2013} has yielded efficient
methods for achieving this goal. Korobeynikov~\citep{Korobeynikov2009}
proposed an algorithm that employs the Fast Fourier Transform (FFT)
for implementing this matrix-vector product by embedding the Markov
parameters into the column vectors of a circulant matrix. This is
suitable for applications wherein the Hankel matrix is composed of
scalar entries such as that formed by the Markov parameters of a single
input single output (SISO) transfer function. Golyandina and Usevich~\citep{GolyandinaKorobeynikovShlemovEtAl2015,GolyandinaUsevich2004}
extended this approach to a generic 2D-case for performing Singular
Spectrum Analysis (SSA) on images. With this modification, this algorithm
is rendered capable of handling the structure of Multi-level Block-Hankel
matrices formed from the Markov parameters of a generic Multi-Input-Multi-Output
(MIMO) system. While the modified scheme does not construct the Block-Hankel
matrix in memory, the operational rubrics of the Golyandina-Usevich
algorithm in conjunction with PROPACK is such that they iteratively
operate on a virtual Hankel matrix of equivalent size. The Golyandina-Usevich
algorithm is briefly summarized in Appendix \ref{sec:Golyandina-Usevich-Algorithm}.

\subsection{Customizations for Battery Modeling}

Specific considerations are required for incorporating the Golyandina-Usevich
algorithm in the ROM workflow for Li-ion batteries. The classical
DRA architecture is set up to handle Single Input Multiple Output
(SIMO) systems, wherein all transfer functions are derived by considering
only a single input \textendash{} the applied battery current. Thus
the Markov parameters form a 2D matrix wherein each row corresponds
to individual battery transfer functions with columns representing
unit-pulse response samples for each transfer function. The 2D moving-window
illustrated in \citep{GolyandinaKorobeynikovShlemovEtAl2015} for
Block-Hankel matrix formulation has to be suitably reshaped to account
for this structure. Step-3 of the algorithm deals with 2-D FFT computation
of the Markov Parameter Matrix (MPM). In our implementation, this
is pre-computed as it remains invariant between iterations of the
Hankel-vector product computation loop. This pre-allocation and a
priori computation contributes to overall code efficiency.

Figure~\ref{improved_ROM_workflow} shows the ROM workflow with
the improved DRA wherein all computational bottlenecks highlighted
by shaded blocks in Figure~\ref{traditional_ROM_Workflow} have
been eliminated. The strategy is to first employ the (suitably modified)
Golyandina-Usevich algorithm for describing the matrix-vector multiplication
routines. These two functions are then used as inputs to the PROPACK
codes. Eigentriplets up to the desired upper bound on system order
is then computed using a Lanczos SVD iteration. Figure~\ref{svdcompare}
presents a comparison of singular values computed by both the  traditional
and new methodologies. It is evident that the two sets of singular
values are identical. Hence, this new scheme can serve as a drop-in
replacement for the classical DRA.

\begin{figure}
	\caption{}
	\label{svdcompare}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Simulation Results and Discussion\label{sec:Results} }

In this section, we quantitatively demonstrate the reduced computational
demand of the improved DRA scheme by comparing it against the classical
DRA implementation. The physical parameters of the cell are the same
as those published in Doyle et al.\citep{FullerDoyleNewman1994}.
Table~\ref{table:simparams} lists the parameters used in the ROM
workflow, which are the same as those employed by Lee~et~al.\citep{LeeChemistruckPlett2012}.

\begin{figure}
	\caption{}
	\label{memory}
\end{figure}

Figure~\ref{memory} shows a comparison of the memory usage of
classical and improved DRA methods. It is evident that the SVD step
in classical DRA consumes an overwhelming majority of the total memory
demand, requiring approximately 100 GB for a Hankel block size of
8000. This can be a limiting factor in modeling slow cell dynamics
without access to a large memory workstation. The improved DRA method
eliminates this bottleneck and the memory usage of SVD step is trivial.
Overall memory usage of the improved DRA is dominated by Markov parameter
computation. Considering 10 GB of usable RAM, 60000 Markov parameters
(Hankel Block-size of 30000) can be captured.

Figure~\ref{cputime} shows a comparison of CPU times for computing
the ROM at a single SoC and temperature for the classical and improved
DRA methods. Appendix \ref{sec:Specifications-of-Workstation} lists the specifications
of the workstation used for the computations. Owing to the high flop
count for SVD operation (eq.~\ref{eq:cpu_op_count}), the classical
DRA requires approximately 40 minutes for a Hankel block size of 8000.
Clearly, the overall CPU time for classical DRA is almost exclusively
used in computing the SVD. The improved DRA method reduces the overall
computational time by two orders of magnitude, taking approximately
40 seconds for the same block-size. In this case, CPU time is evenly
split between SVD and Markov parameters computations.

\begin{figure}
	\caption{}
	\label{cputime}
\end{figure}

From Figure~\ref{memory}, it is evident that if classical DRA
is employed, a standard laptop with a nominal 10 GB RAM limit (dedicated
for ROM workflow) cannot capture the full cell dynamics and hence
is restricted to 2500 Hankel blocks. This necessitates early truncation
of Markov parameters at 5000 seconds. From Figure~\ref{markov_cse_pos},
the truncation residue at 5000 seconds for the unit-pulse response
of solid surface concentration at positive current collector is $-0.0087 \text{ mol m}^{-\text{3}}$.
The truncation errors in the Markov Parameter Matrix directly translate
to errors in computed singular values, adversely affecting accuracy
of simulated cell variables. It must be noted that the accuracy of
simulation results reported here does not bear a causal relationship
to the particular DRA scheme employed. In-principle, when an upper
bound on computational usage has not been enforced, the numerical
operations of both the existing and proposed DRA schemes lead to similar
error magnitudes for the modeled quantities. Instead, the accuracy
comparison illustrated here primarily serves to demonstrate the practical
usefulness of the improved DRA scheme when implemented in a commonplace
computing environment.

\begin{figure}
	\caption{}
	\label{truncated}
\end{figure}

Figure~\ref{truncated} shows a comparison of singular values obtained
by the classical and improved SVD methods computed by imposing a RAM
limit of 10GB. Owing to early truncation of the Markov parameter matrix,
the dominant singular values computed by the conventional method differ
significantly from those computed by the improved SVD operating on
untruncated data. With the same memory constraints, the improved DRA
can handle up to 30000 Hankel blocks, allowing for capture of 60000
seconds of Markov parameter data.

For comparative analysis of modeling accuracy under this memory constraint,
a time-domain simulation of the ROMs obtained by classical and improved
DRA methods is performed. The input current profile corresponding
to UDDS drive cycle reported in Lee~et~al. \citep{LeeChemistruckPlett2012}
is used. Figure~\ref{time_domain_sim} depicts the time-evolution
of the solid surface concentration at the positive electrode/separator
boundary. For comparing the accuracy of the two ROMs, a COMSOL Multiphysics~\citep{Multiphysics2012}
simulation of the full-order pseudo-2D porous-electrode PDE model
is used as the reference. The ROM employing classical DRA diverges
over time, and after 1500 seconds results in an error of 1120$\text{ mol m}^{-\text{3}}$$.$
The ROM incorporating the new DRA workflow accurately tracks the COMSOL
simulation trend-line. Table~\ref{table:salientresults} provides
a summary of the key simulation results.

\begin{figure}
	\caption{}
	\label{time_domain_sim}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions\label{sec:Conclusion}}
In this paper, Singular Value Decomposition of a large Block-Hankel
matrix is identified as a key bottleneck in the classical DRA for
reduced-order Li-ion cell modeling. An improved SVD scheme is presented,
which employs a combination of the Golyandina-Usevich and Lanczos
algorithms. The results discussed in Section \ref{sec:Results} demonstrate
the performance improvement achieved by the new method without trading-off
model fidelity. At a single operating point of SoC and temperature,
for a Hankel block size of 8000, ROM workflow incorporating the improved
DRA is approximately 100 times faster than that employing classical
DRA. Using the machine specifications in Appenndix  \ref{sec:Specifications-of-Workstation},
for 100 operating points (combinations of 10 SoC and temperature values),
computing the ROM requires only 6 hours using the improved DRA, whereas
the classical DRA consumes 666 hours (27 days). Furthermore, for the
same block-size, the improved DRA is demonstrated to be superior in
terms of memory efficiency, drastically reducing the memory requirement
from 112 GB down to 2 GB. Finally, the improved DRA demonstrates superior
modeling accuracy when implemented even in moderately equipped computing
environments such as laptops.

The proposed method leads to the possibility of modeling other physical
quantities in the cell geometry unhindered by computing limitations.
Furthermore, high sample-rate models to handle highly dynamic load
profiles can be deployed in future BMS applications. The scheme also
empowers the ROM framework to tackle cells with slower dynamics and
other chemistries with different rate-limiting mechanisms. The improved
DRA method opens up a wide range of possibilities and brings the goal
of physics-based battery model implementation in a high performance
real-time BMS a step closer to realization.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{acknowledgment}
Financial support for the research reported in this paper has been
obtained through the Imperial College President's PhD Scholarships
scheme. The sponsor had no role whatsoever in collection, analysis
and interpretation of data, or in writing of the manuscript. Furthermore,
the funding body has no role/involvement in the decision to submit
the article for publication. The authors wish to acknowledge the support
of The Department of Mathematics, Imperial College London for usage
of the departmental computing cluster. The CPU times, memory usage
and all other computational results reported in this paper were obtained
by using a computing node from this facility.
\end{acknowledgment}

\begin{nomenclature}
	\entry{$c_e \scriptstyle(x,t)$}{Concentration of Li$^\text{+}$ ions in the electrolyte at each spatial location within the 1-D cell geometry $(\text{mol m}^{-\text{3}})$}
	\entry{$c_{s,e} \scriptstyle(z,t) $}{Concentration of Li at the surface of each solid particle within the normalized domain length of each electrode $(\text{mol m}^{-\text{3}})$}
	\entry{$\medmuskip=0mu \tilde{c}_{\scriptscriptstyle s,e_{pos}}^*\scriptstyle(0,t) $}{Surface concentration of Li in the solid particle adjacent to positive current collector, obtained after model linearisation and subsequent removal of the integrator pole. The algorithms discussed in this paper require that all model variables have poles located strictly within the open left-half complex plane. Since the solid diffusion transfer functions have poles at the origin, it is necessary to remove this integrator pole before deriving the model $(\text{mol m}^{-\text{3}})$}
	\entry{$L_{neg}$}{Thickness of the negative electrode $(\text{m})$}
	\entry{$L_{sep}$}{Thickness of the separator domain $(\text{m})$}
	\entry{$L_{pos}$}{Thickness of the positive electrode $(\text{m})$}
	\entry{$j \scriptstyle(z,t) $}{Li molar flux density at electrode-electrolye interface of each particle within the normalized electrode domain $(\text{mol m}^{-\text{2}}s^{-\text{1}})$}
	\entry{$\phi_e \scriptstyle(x,t) $}{Electrolyte potential at each spatial location within the 1-D cell geometry $(\text{V})$}
	\entry{$\phi_{s,e} \scriptstyle(z,t) $}{Solid-electrolyte potential difference at the inteerfacial boundary for each spatial location within the 1-D cell geometry $(\text{V})$}
\end{nomenclature}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{asmems4}
\bibliography{SVD_paper_Bibliography}
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix %%% starting appendix
\section{Golyandina-Usevich Algorithm\label{sec:Golyandina-Usevich-Algorithm}}

The Golyandina-Usevich algorithm is used for computing the product
of a Block-Hankel matrix with an arbitrary vector. The steps involved
in this scheme are enumerated in Algorithm 3 of \citep{GolyandinaKorobeynikovShlemovEtAl2015}.
These steps are reproduced here in the context of discrete-time realization
algorithm for reduced order battery modeling.
\begin{enumerate}
	\item Compute a 2-D FFT of Markov parameter matrix.
	\item Form an augmented vector by zero-padding the arbitrary vector input
	from Lanczos iteration.
	\item Perform a column-wise reshaping of this augmented vector to obtain
	a new matrix with the same dimensions of the Markov parameter matrix.
	\item Compute the element-wise product of this newly created matrix with
	the 2-D FFT of Markov parameter matrix.
	\item Reshape the resulting matrix back to a column vector.
	\item Extract the first $L$ elements from this vector, wherein $L=Kx$.
	$K$ represents the desired block-Hankel size and $x$ represents
	the number of transfer functions being modeled.
\end{enumerate}
At the end of Step 6, the product of the Hankel matrix and arbitrary
vector is obtained. This is reused as an input for the Lanczos scheme
which generates a new arbitrary vector in the subsequent iteration.
Thus, the steps 1\textendash 6 are run in a loop within the main Lanczos
scheme. These same steps can also be used for computing the product
of the transpose of the Hankel matrix and the arbitrary vector. The
only change is to account for the different dimensions of the arbitrary
vector input from the Lanczos scheme in step 2. As a practical implementation,
software code representing steps 1\textendash 6 is written in a plain-text
file and used as functional-form inputs by the PROPACK scheme which
implements the Lanczos iteration.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\singlespacing
\section{Specifications of Workstation Used\label{sec:Specifications-of-Workstation}}

\newpage
\section*{Listing of Table Captions}

\begin{description}
	\item[Table 1]   Parameters for ROM Computation\\
	\item[Table 2]   Salient Results - Classical vs. Improved DRA\\
	\item[Table 3]   Specifications of workstation used
\end{description}
\newpage
\section*{Listing of Figure Captions}

\begin{description}
	\item[Fig. 1.]   Reduced-order modelling (ROM) workflow using classical DRA.\\ (The shaded blocks represent computational bottlenecks).\\
	\item[Fig. 2.]   Time evolution of Markov parameters of pole-removed transfer function corresponding to surface concentration of Li in the solid particle adjacent to positive current collector.\\
	\item[Fig. 3.]   Reduced Order Modelling (ROM) Workflow using improved DRA.\\
	\item[Fig. 4.]   Comparison of singular values computed by the conventional and improved SVD methods.\\
	\item[Fig. 5.]	 Memory usage of classical and improved DRA. Overall RAM usage as well as RAM used only for SVD computation is illustrated.\\
	\item[Fig. 6.] 	 Computation times for classical and improved DRA schemes.\\
	\item[Fig. 7.]	 Comparison of singular values computed by conventional and improved SVD methods under a practical RAM limit of 10 GB.\\
	\item[Fig. 8.]	 Time-domain simulation depicting solid surface concentrations at the boundary of positive electrode and separator.\\
\end{description}

\newpage
\singlespacing
\begin{table}[h]
	\begin{center}
		\caption{Parameters for ROM Computation}
		\label{table:simparams}
		\begin{tabular}{ l l }
			\hline
			Initial Cell SoC & 60 \%  \\
			Hankel Block Size & 8000 \\
			Discrete-Time Model Sample-Rate,$T_s$ & 1 sec  \\
			Number of Electrolyte EigenModes & 5 \\
			Continuous-Time Emulation Frequency, $F_1$ & 128 Hz \\
			Desired Number of Singular Values &	10 \\
			\hline
		\end{tabular}
	\end{center}
\end{table}

\newpage
\singlespacing

\begin{table}[h]
	\singlespacing
	\centering
	\caption{Salient Results - Classical vs. Improved DRA}
	\label{table:salientresults}
	\setlength{\extrarowheight}{1pt}
	%\centering
	\begin{tabular}{ c c c c }
		\hline
		ROM & Quantity 		& Classical & Improved \\
		Condition		   &				  & DRA		 & DRA	  \\
		\hline
		\multirow{8}{1.22cm}{8000 Hankel Blocks}& Memory 		  & 111.80 GB	  & 2.14 GB  \\[-5pt]
		& \footnotesize (overall)		&			 & 		 \\
		& Memory 		  & 97.93 GB	  & 0.03 GB  \\[-5pt]
		& \footnotesize(SVD step)   	&			 & 		 \\
		& CPU Time 		& 39.78 min   & 0.63 min  \\[-5pt]
		& \footnotesize(overall)    	&			 & 		 \\
		& CPU Time 		& 39.30 min   & 0.14 min  \\[-5pt]
		& \footnotesize(SVD step)   	&			 & 		 \\[2.5pt]
		\hline
		\multirow{3}{1.22cm}{10 GB Memory Limit}& Block Size		  & 2500	  & 30000  \\[5pt]
		& Max. error & 1120\scriptsize $\text{ mol m}^{-\text{3}}$ &  13\scriptsize $\text{ mol m}^{-\text{3}}$ \\[-5pt]
		& in $c_{{s,e}_{pos}}$\scriptsize $(1,t)$ &  &     \\[5pt]
		\hline
	\end{tabular}
\end{table}
\newpage
\begin{table}[h]
	\caption{Specifications of workstation used}
	\label{table:comp_spec}
	\centering
	\begin{tabular}{ l l }
		\hline
		Processor & Intel\textregistered\space  Xeon \textregistered\space E5-2637 v3 \\
		Used Cores & 1 \\
		CPU Stepping & 2 \\
		Clock Frequency & 3.50 GHz \\
		Installed RAM & 500 GB \\
		\hline
	\end{tabular}
\end{table}


% achieve the latent  potential and wide applicability  of the
% physics-based reduced order Li-ion battery model.

