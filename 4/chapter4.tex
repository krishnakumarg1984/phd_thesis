% -*- root: ../main.tex -*-
%!TEX root = ../main.tex
% this file is called up by main.tex
% content in this file will be fed into the main document
% vim:textwidth=80 fo=cqt

\graphicspath{{4/figures/}}
% ----------------------- contents from here ------------------------

\chapter{Computational Analysis and Numerical Reformulation of the \glsfmtshort{dra}}\label{ch:improveddra}
% \chapter{Analysis of the \glsfmtlong{dra} and Performance Boost through Numerical Reformulation}\label{ch:improveddra}
% \chapter{Computational Bottleneck Analysis of the \glsfmtshort{dra} and its Mitigation through Numerical Reformulations}\label{ch:improveddra}
\startcontents[chapters]
\printcontents[chapters]{}{1}{\setcounter{tocdepth}{1}}

\bigskip

\capolettera{T}{his} chapter presents  an analysis and critical  evaluation of a
computational bottleneck present in  a popular physics-based \gls{rom} framework
of lithium-ion batteries and proposes  an alternative numerical reformulation to
mitigate  it\footnote{This  chapter is  based  on  the journal  publication  ---
\fullcite{Gopalakrishnan2017}.  All  intellectual  ideas in  the  aforementioned
article  are original  contributions of  this thesis  author. All  text, tables,
figures  and captions  therein were  contributed solely  by this  thesis author.
Copyright  clearance for  non-commercial  verbatim reproduction  of the  content
(such as in this thesis) has been secured through the publication agreement with
the  copyright holder  ASME (see  \cref{ch:permissions}). The  contents in  this
chapter may be, in full or in part, included verbatim from the said publication.
This  author wishes  to express  his thankfulness  to Teng  Zhang, co-author  of
this  article, for  checking  my calculations  and  providing valuable  feedback
that  helped to  refine  the  manuscript for  that  journal publication.}.  From
the  literature review  presented in  \cref{ch:littreview}, it  may be  recalled
that  transcendental  transfer functions  of  the  cell's electrochemical  field
variables  (except for  ionic concentration  and potential  in the  electrolyte)
was  obtained  by  Smith~\etal~\cite{Smith2007}  through  linearisation  of  the
underlying \gls{p2d} model equations. Lee~\etal~\cite{Lee2012a,Lee2012} extended
the aforementioned approach  so as to obtain  these missing electrolyte-specific
transfer  functions through  a multi-modal  EigenFunction expansion  employing a
Sturm-Liouville approach~\cite{Pryce1993}.


In order to arrive at a  \gls{lti} state-space representation of the system (see
\cref{eq:LTIstatespace})  for embedded  implementation, Lee~\etal{}  devised the
\gls{dra}, a numerical procedure  to systematically transform all transcendental
transfer functions  to the time domain.  A special property of  the \gls{dra} is
that it  retains the physical nature  of the original \gls{dfn}  equations until
the very  last step  wherein the  matrices governing  the system's  dynamics are
generated. This  yields a  one-dimensional discrete-time  \gls{rom} of  the cell
that is entirely based upon  fundamental physical principles. The \gls{rom} thus
obtained could  then be used to  compute the time-evolution of  all the internal
electrochemical quantities of  the \gls{dfn} model. Prima~facie  it appears that
this model  could be directly  implemented for embedded  vehicular applications,
for  example,  as  the  plant  model for  state  estimation  tasks.  However,  a
comprehensive analysis  of the procedure reveals  a critical issue that  must be
first tackled before implementation aspects can be considered.

The  unresolved  issue in  Lee~\etal{}  is  the excessively  high  computational
requirements associated with the \gls{dra}, which becomes a crippling bottleneck
since  the  procedure  needs  to   be  repeated  for  multiple  \glspl{soc}  and
temperatures.  This  computational  bottleneck   arises  from  forming  a  large
Block-Hankel  matrix  in memory  upon  which  a  \gls{svd} is  performed.  Under
certain conditions  as discussed in  \cref{sec:size-of-the}, owing to  the large
size  of  the  Block-Hankel  matrix,   the  \gls{dra}  computation  is  rendered
intractable. This issue has been acknowledged by the original authors themselves
in~\cite{Lee2012,Plett2015}.  In  this  chapter, this  computational  bottleneck
is  analysed  and an  improved  scheme  is proposed.  \Cref{sec:Analysis-of-the}
discusses an analytical evaluation of  the massive computing requirements of the
original  \gls{dra} method.  Redundancies and  inefficiencies in  this step  are
enumerated  and the  high  computational  costs are  deemed  as unnecessary.  In
\cref{sec:Efficient-Computation-of}, a fast  computational approach is presented
which  significantly reduces  both  the  memory and  computational  time of  the
\gls{rom}  workflow. \Cref{sec:Results}  summarizes  the  results obtained  from
applying the  new workflow presented in  \cref{sec:Efficient-Computation-of}, by
comparing and contrasting the much smaller computational requirements of the new
method  with the  original  \gls{dra} scheme.  The  improved modelling  accuracy
achieved  by  this  proposed  method when  deployed  under  resource-constrained
computing environments, is also highlighted. \Cref{sec:Conclusion} concludes the
chapter  with a  view that  although  the improved  methodology streamlines  the
entire  workflow,  there exist  some  fundamental  deficiencies in  this  hybrid
modelling approach  that impede its effective  deployment as the plant  model in
state estimation tasks.

\section{Analysis of the Computational Bottlenecks of the \glsfmtshort{dra}}\label{sec:Analysis-of-the}

The \gls{rom}  proposed by  Lee~\etal{} aims  for the  simplified representation
of  the  \glsfirst{p2d}  volume-averaged  continuum  model  proposed  by  Doyle,
Fuller   and   Newman~\cite{Doyle1993a,Fuller1994}\footnote{hereafter   referred
    interchangeably in  this thesis  by the two  acronyms ---  \glsfmtshort{dfn} and
\glsfmtshort{p2d}.}.


The   block   diagram   in  \cref{fig:traditional_ROM_Workflow}   depicts   this
thesis  author's   summary  presentation  of  the   overall  modelling  workflow
in   Lee~\etal{}.   Firstly,  the   governing   \gls{pdae}   equations  of   the
\gls{dfn}  model  (see \cref{tbl:dfneqns})  are  linearised  about an  operating
point   of  \gls{soc}   and  temperature.   Then,  closed-form   Laplace  domain
transcendental  transfer  functions  of  all the  internal  physical  quantities
$\left(\phi_{s},\phi_{e},c_{s},c_{e},j\right)$  at   different  cell  locations,
are  derived  using applied  current  as  the  input.  A detailed  treatment  of
this  analytical  derivation  is  presented  in  Lee~\etal~\cite{Lee2012a}.  The
authors  proposed  a novel  \glsfirst{dra}  scheme~\cite{Lee2012b}  in order  to
transform  these  transcendental  transfer  functions  to  standard  state-space
representation.  Sublevel-1   of  \cref{fig:traditional_ROM_Workflow}   shows  a
breakout view of  the \gls{dra} procedure and illustrates the  steps involved in
this  computation. At  the  heart  of this  numerical  method  is the  classical
subspace  identification approach  known as  Ho-Kalman algorithm~\cite{HO1966a},
whose  computation steps  are  shown  via the  exploded  view  in sublevel-2  of
\cref{fig:traditional_ROM_Workflow}.  Then,  the Markov  parameters  (unit-pulse
response) of  this \gls{simo}  linear system of  battery transfer  functions are
computed\footnote{A  ubiquitous concept  in linear  systems and  control theory,
Markov parameters  represent the discrete-time  unit pulse response of  a linear
system.}.  They  form the  entries  of  a Block-Hankel  matrix~\cite{Ljung1998},
wherein each block  element is a column  vector of the set  of Markov parameters
at  a  given  time-step.  A  key  computation  in  the  Ho-Kalman  algorithm  is
the  \glsfirst{svd}  of this  Block-Hankel  matrix.  A  wide separation  in  the
magnitude  drop  between  successive  singular  values serves  as  a  guide  for
the  modeller in  choosing  a suitable  reduced order  to  represent the  entire
dynamics  of  the  system.  The   analyses  of  this  thesis  author,  presented
in \cref{subsec:Traditional-DRA--Memory}  and \cref{subsec:Traditional-DRA--CPU}
reveal major inefficiencies in both the Block-Hankel formation and the \gls{svd}
computation steps which hinder the entire reduced-order modelling workflow.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\textwidth]{traditional_dra.pdf}
    \caption[%
    \glsfmtshort{rom} workflow using classical \glsfmtshort{dra}.
    ]%
    {%
        Reduced-order modelling (ROM) workflow using classical
        \glsfmtshort{dra}. The shaded blocks represent computational bottlenecks.
    }%
    \label{fig:traditional_ROM_Workflow}
\end{figure}

\subsection{Size of the Block-Hankel Matrix}\label{sec:size-of-the}

Large Block-Hankel matrices can occur in \gls{dra} computation due to the
following reasons.
\begin{enumerate}
    \item
        For  a  given   duration  of  Markov-parameter  recording,   if  a  high
        sample-rate   \gls{rom}  is   desired,   the   emulation  frequency   in
        the   \gls{dra}  scheme   has   to  be   proportionately  increased   to
        accurately  compute  the continuous-time  step  and  pulse responses  in
        \cref{fig:traditional_ROM_Workflow}. This implies  that the total number
        of time-samples~$N$  for each  Markov parameter will  have to  be scaled
        linearly to  capture the  desired duration  of the  unit-pulse response.
        However,  the size  of the  Block-Hankel matrix  has a  \emph{quadratic}
        dependence on the Markov parameter length.
    \item
        The  recorded sample  size~$N$ could  also  become large  if the  Markov
        parameters of just  one of the transfer functions decay  very slowly. In
        Li-ion batteries, diffusion  within the solid particle  is typically the
        slowest process.  For the cell  modelled in Lee~\etal{},  the unit-pulse
        response of surface concentration of Li adjacent to the positive current
        collector  requires approximately  16000~samples before  reducing to  an
        appreciably low value, as shown in~\cref{fig:markov_cse_pos}.
    \item
        For  a  battery  modelling   problem  consisting  of  multiple  transfer
        functions,  the  number  of  entries in  the  Block-Hankel  matrix  also
        scales linearly  with the  number of transfer  functions. Thus,  if more
        cell  variables (\eg{}  concentrations and  potentials at  other spatial
        locations  within the  cell) are  to be  studied, then  the size  of the
        transfer function vector  and that of the  Block-Hankel matrix increases
        correspondingly.
\end{enumerate}

\begin{figure}[!htbp]
    \centering
    \includegraphics{markov_decay.pdf}
    \caption[Markov parameters of solid surface concentration at positive
    current collector]{Time evolution of Markov parameters of pole-removed transfer
        function corresponding to surface concentration of Li in the solid particle
    adjacent to positive current collector.}
    \label{fig:markov_cse_pos}
\end{figure}

Considering the combined  influence of these effects, if  $x$ transfer functions
are to  be modelled  and $N$  time-samples of  each Markov  parameter are  to be
captured, the corresponding size of the Block-Hankel matrix~$H$ is
\begin{equation}
    \text{Size}(H)\sim \mathcal{O}(x N^2)\text{ {entries}}
\end{equation}

This    has    a    significant     computational    impact    as    shown    in
\cref{subsec:Traditional-DRA--Memory} and \cref{subsec:Traditional-DRA--CPU}.

\subsection{Classical \glsfmtshort{dra} --- Memory (\glsfmtshort{ram}) Requirements}\label{subsec:Traditional-DRA--Memory}

Lee~\etal~\cite{Lee2012a}  modelled 28~transfer  functions representing  various
electrochemical  variables at  the current  collector and  separator interfaces.
Each Markov  parameter is  a 28~element  column vector.  16000~time-samples were
obtained at  a sample-rate of  \SI{1}{\hertz}, allowing sufficient time  for the
Markov parameters of  the slowest dynamics \ie{} solid  surface concentration to
settle to an  acceptably low magnitude. The Block-Hankel matrix  thus formed has
8000~blocks,  each  block  consisting  of 28~elements  \ie{}  has  $8000  \times
28=224000$~rows  and 8000~columns.  Hence,  the overall  number  of elements  in
the  Block-Hankel  matrix is  $224000  \times  8000=1.79 \times  10^{9}$.  Using
double-precision  arithmetic, its  storage requirement  can be  estimated to  be
\approx \SI{27}{\giga\byte}.

Computing the \gls{svd} results in the formation of three more large matrices in
memory ---
\begin{enumerate*}[label=\roman*)]
    \item matrix   of   output  singular   vectors~$U$,
    \item matrix of  input  singular vectors~$V$, and
    \item the diagonal singular-value  matrix~$\Sigma$.
\end{enumerate*}
With  8000~Hankel-blocks,  approximately  \SI{81}{\giga\byte}  of  \gls{ram}  is
required for holding these three output  matrices generated by a full \gls{svd}.
However,  the  intermediate  operational   memory  usage  during  the  \gls{svd}
computation is often much higher than the  combined size of all the matrices. As
these large  matrices must  be repeatedly  handled for  each operating  point of
\gls{soc} and  temperature, the  high memory demand  of the  classical \gls{dra}
remains a persistent issue.

\subsection{Classical \glsfmtshort{dra} --- \glsfmtshort{cpu} Operation Count}\label{subsec:Traditional-DRA--CPU}

The most  widely used numerical  algorithm for  computing the full  \gls{svd} of
a  generic  dense  matrix $\mbox{\ensuremath{A\in\mathbb{R}^{m  \times  n},m\geq
n}}$  is  the  two-stage  Golub-Kahan-Reinsch  method~\cite{Golub2013}.  In  the
first  stage $A\in\mathbb{R}^{m  \times n}$  is reduced  to an  upper bidiagonal
form.  In  the  second  stage,   \gls{svd}  of  this  upper  bidiagonal  matrix,
$B\in\mathbb{R}^{m  \times n}$  is computed  using an  iterative procedure  such
as  the Demmel-Kahan  method~\cite{Golub2013}. If  stage~\romanletter{1} of  the
\gls{svd}  computation employs  $\mathbb{R}$-Bidiagonalization~\cite{Golub2013},
then the overall  process is referred to as $\mathbb{R}$-\gls{svd}.  This is the
fastest known  full \gls{svd}  computation method  that may  be applied  to this
battery modelling problem. The \textsc{dgesvd} algorithm, originally implemented
in  \textsc{LAPACK}~\cite{Anderson1999},  employs  this method.  This  has  been
ported to  many numerical computation  packages such  as MATLAB, GNU  Octave and
Scilab.  Several  numerical  libraries  such  as NAG  and  Intel  MKL  also  use
the  \textsc{dgesvd}  codes  due  to its  acclaimed  stability,  robustness  and
versatility.  The MATLAB  implementation `\texttt{\textbf{svd}}'  is also  based
upon \textsc{dgesvd} and  hence this can be considered as  the de-facto baseline
\gls{svd} code.

The    operation    count    for    computing   the    singular    values    and
vectors   of  a   generic   dense  matrix   $\mbox{\ensuremath{A\in\mathbb{R}^{m
\times   n},m\geq    n}}$   using    the   $\mathbb{R}$-\gls{svd}    method   is
$\mbox{\ensuremath{4m^{2}n+22n^{3}}}$~\cite{Golub2013}.  Markov   parameters  of
$x$~transfer functions  and $N$~time-samples  yields a Block-Hankel  matrix with
$m=x N$ rows and $n=N$ columns. Hence,
\begin{alignat}{2}
    \text{\glsfmtshort{cpu} Operation  Count} & = & \,4\left(xN\right){}^{2}N+22N^{3}\nonumber \\
                                              & = & \,2N^{3}\left(11+2x^{2}\right)\label{eq:cpu_op_count}
\end{alignat}
Thus  the \gls{cpu}  operation  count scales  as  $\mathcal{O}(N^{3})$ with  the
number of Markov time-samples~$N$ and as $\mathcal{O}(x^{2})$ with the number of
transfer  functions~$x$ being  modelled. The  \gls{rom} computed  in Lee~\etal{}
uses  28~transfer functions  wherein  the Markov  parameters  are collected  for
\SI{16000}{\second}  with  a sampling  interval  of  \SI{1}{\second}. Thus,  the
\gls{cpu}  operation  count for  performing  this  computation is  approximately
$\mathcal{O}(16000^{3})\approx 4 \times 10^{12}$ floating point operations.

\subsection{Summary Effect of Computational Bottlenecks}\label{subsec:Summary-Effect-of}

The computational bottleneck in a  classical \gls{dra} implementation arises due
to the  requirement of capturing a  large number of Markov  parameters, which in
turn leads  to growth in  Block-Hankel size. In  the case of  battery modelling,
this can arise in the following real-life scenarios:
\begin{enumerate}
	\item
        Electrochemical variables at additional locations of interest within the
        cell (\eg{}  middle of electrode or  separator domain) might need  to be
        modelled. This increases the number  of transfer functions and hence the
        number of Markov parameters.
	\item
        High frequency load  cycles necessitate higher sample-rates  to obtain a
        high fidelity  model. This leads  to a correspondingly higher  number of
        Markov parameters.
	\item
        In cells with  large particle sizes and small  diffusion coefficients, a
        large set  of Markov  parameters is  needed to  capture the  full system
        dynamics.
\end{enumerate}
Lack  of  specialized  computing infrastructure  necessitates  early  truncation
of  the  Markov parameters  in  the  \gls{rom}  workflow. The  resulting  errors
in  the singular  value  computation  lead to  significant  modelling errors  in
the  physical  variables of  the  cell.  Thus,  in practice,  the  computational
bottlenecks of classical \gls{dra} manifest as modelling errors when implemented
in  a  resource-constrained  computing environment.  Furthermore,  this  tedious
computation has to be repeated for multiple \glspl{soc} and temperatures.

The foregoing analysis  clearly demonstrates that the high  memory and \gls{cpu}
demands in  a classical \gls{dra}  implementation severely hamper the  scope and
applicability  of the  reduced order  modelling process.  This implies  that the
modelling  workflow is  not accessible  to research  groups without  specialized
computing infrastructure and its universal  appeal is rendered questionable. The
shaded  blocks in  \cref{fig:traditional_ROM_Workflow}  depict the  hierarchical
propagation of the classical \gls{dra}'s computational bottleneck throughout the
\gls{rom} workflow.

\section{Improved \glsfmtshort{dra} for Battery Modelling}\label{sec:Efficient-Computation-of}

Collecting a  large Markov parameter  set is  inevitable due to  the fundamental
physics of the cell  dynamics as established in \cref{subsec:Summary-Effect-of}.
Hence, in  order to circumvent the  high computational demands of  the classical
\gls{dra}, the second step in the process \ie{} forming the Block-Hankel matrix,
is critically examined with the following scientific rationale.

\begin{enumerate}
	\item
        The unit-pulse responses of most  battery transfer functions (other than
        those of rate-limiting  steps such as solid  diffusion) decay relatively
        quickly. Hence it is inefficient to  record the Markov parameters of the
        full  system for  the  entire  duration needed  to  capture the  slowest
        dynamics.
	\item
        The Block-Hankel  matrix is essentially redundant  information since its
        entries are simply the Markov parameters arranged in a repeating special
        structure. Thus,  it is wasteful to  construct this huge matrix.  If the
        \gls{svd} operation  can be  performed on a  virtual Hankel  matrix, the
        memory requirements can be drastically reduced.
	\item
        The matrix of singular values~$\Sigma$ is diagonal and hence, sparse. It
        is redundant to hold all the non-diagonal entries (zeros) in memory.
	\item
        It  is not  necessary to  perform a  \emph{full} \gls{svd}  operation in
        order  to  achieve order  reduction.  When  an  upper bound  on  desired
        system order  can be  decided a  priori, it is  sufficient to  compute a
        \emph{truncated} \gls{svd}  yielding the first few  dominant triplets of
        $U, \Sigma \text{ and } V$.
\end{enumerate}
Thus,  forming the  large Block-Hankel  matrix  and computing  its \gls{svd}  is
identified as an avoidable bottleneck in the classical \gls{dra}method. This can
be  tackled since  forming the  Block-Hankel matrix  is an  idiosyncrasy of  the
algorithm  used  and  does  not  arise from  any  fundamental  physical  limits.
Facilitated  by  an  efficient  \gls{svd}  implementation,  this  thesis  author
proposes  an improved  \gls{dra}that  serves  as a  drop-in  replacement in  the
\gls{rom} workflow.

\subsection{Candidate Schemes for Block-Hankel \glsfmtshort{svd}}

Generic  \gls{svd}  routines  such  as \textsc{dgesvd}  do  not  take  advantage
of  the  anti-diagonal  structural  symmetry  of  Block-Hankel  matrices.  Since
it  is sufficient  to  obtain  the first  few  leading  eigentriplets for  order
reduction,  iterative  algorithms  such  as   the  Jacobi  and  Lanczos  schemes
(see~\cite{Golub2013}  emerge  as  attractive  candidates  for  computing  these
dominant singular  values and vectors. In  order to ensure accessibility  to the
large community of  battery researchers and to encourage  widespread adoption of
the fast reduced order modelling framework, the author of this thesis considered
only freely available  open-source numerical libraries that exist  in the public
domain, especially  those with permissive  licensing terms. Otherwise  the gains
achieved by  an efficient  \gls{svd} computation  for implementing  \gls{dra} on
non-specialized  computing  hardware would  be  offset  by commercial  licensing
terms,  usage restrictions  and  monetary considerations  associated with  using
proprietary  codes. Among  these  open-source candidate  algorithms, the  Jacobi
scheme~\cite{Golub2013} is  available through the  xGESVD routine in  the LAPACK
suite~\cite{Anderson1999}. FORTRAN 77 codes for the implicitly restarted Arnoldi
and Lanczos schemes~(see~nu-TrLan~\cite{Yamazaki2008}) are  available as part of
the ARPACK~\cite{Lehoucq1998} library.

The practical drawback  of most \gls{svd} implementations,  both open-source and
proprietary, is  that they require  the entire  matrix as input  argument. Since
operating upon  the Block-Hankel  matrix requires constructing  it in  the first
place, the memory bottlenecks discussed in \cref{subsec:Traditional-DRA--Memory}
are  not  ameliorated. An  example  is  the  \texttt{svds} routine,  an  economy
size  \gls{svd}   implementation  in  MATLAB.   Albeit  this  is   a  commercial
implementation  of  the  Arnoldi  codes,  any potential  benefits  of  using  an
iterative scheme is nullified by the memory penalty. Owing to reasons enumerated
in \cref{sec:Efficient-Computation-of}, the chosen  \gls{svd} algorithm needs to
be able to handle the computation without actually forming the huge block-Hankel
matrix in memory.

% \subsection{\gls{svd} Operation on a Virtual Block-Hankel Matrix}

% R.M. Larsen's pioneering work PROPACK~\cite{Larsen2014} implements
% a numerically stable Lanczos \gls{svd} computation designed specifically
% for large and sparse matrices. In addition to the ability to operate
% on the matrix as a whole, the PROPACK codes possess a unique flexibility
% of accepting input arguments in functional form. A key highlight of
% the Lanczos \gls{svd} scheme is that it does not strictly require the matrix
% itself, but only the product of the matrix and its transpose with
% an arbitrary vector. This feature has been effectively exploited in
% the PROPACK suite. Therefore, these multiplication routines can be
% supplied as input arguments instead of forming the large Block-Hankel
% matrices in memory. Furthermore, this package includes sophisticated
% schemes such as Gram-Schmidt partial re-orthogonalization~\cite{Bjoerck1994}
% to compensate for numerical round-off errors in the basic Lanczos
% bidiagonalization and ensures orthogonality of the input and output
% singular vectors. The PROPACK suite is available as both Fortran 77
% and MATLAB codes distributed under a permissive BSD license~\cite{Rosen2005}.

% For the \gls{rom} workflow, in order to use PROPACK's unique feature, i.e.
% its flexibility to accept functional form inputs, the key is to use
% an algorithm that effectively exploits the affine structure of the
% Block-Hankel matrix without actually forming it in memory. Recent
% research in a specialized time-series technique known as Singular
% Spectrum Analysis (SSA)~\cite{ElsnerTsonis2013} has yielded efficient
% methods for achieving this goal. Korobeynikov~\cite{Korobeynikov2009}
% proposed an algorithm that employs the Fast Fourier Transform (FFT)
% for implementing this matrix-vector product by embedding the Markov
% parameters into the column vectors of a circulant matrix. This is
% suitable for applications wherein the Hankel matrix is composed of
% scalar entries such as that formed by the Markov parameters of a single
% input single output (SISO) transfer function. Golyandina and Usevich~\cite{GolyandinaKorobeynikovShlemovEtAl2015,GolyandinaUsevich2004}
% extended this approach to a generic 2D-case for performing Singular
% Spectrum Analysis (SSA) on images. With this modification, this algorithm
% is rendered capable of handling the structure of Multi-level Block-Hankel
% matrices formed from the Markov parameters of a generic Multi-Input-Multi-Output
% (MIMO) system. While the modified scheme does not construct the Block-Hankel
% matrix in memory, the operational rubrics of the Golyandina-Usevich
% algorithm in conjunction with PROPACK is such that they iteratively
% operate on a virtual Hankel matrix of equivalent size. The Golyandina-Usevich
% algorithm is briefly summarized in Appendix \ref{sec:Golyandina-Usevich-Algorithm}.


