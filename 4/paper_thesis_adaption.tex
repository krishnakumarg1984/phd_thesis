%% LyX 2.3.0 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\RequirePackage{fix-cm}
\RequirePackage{fixltx2e}
\documentclass[10pt,twoside,english,a4paper,10pt,twocolumn,preprint,3p]{elsarticle}
\usepackage{tgpagella}
\renewcommand{\ttdefault}{lmtt}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\pagestyle{headings}
\usepackage{algorithm2e}
\usepackage{amsthm}
\usepackage{microtype}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.

\newcommand*{\LyXFourPerEmSpace}{\hskip0.25em\relax}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
% specify here the journal
\journal{Journal of Power Sources}
%\usepackage{mathpazo}
\usepackage{mathtools}
\usepackage[bitstream-charter]{mathdesign}
% use this if you need line numbers
%\usepackage{lineno}

\makeatother

\usepackage{babel}
\providecommand{\theoremname}{Theorem}

\begin{document}

\begin{frontmatter}{}

\title{Fast, Efficient Computation of Reduced Order Model of Li-ion Battery
Dynamics\tnoteref{t1}}

\tnotetext[t1]{The research work presented here was supported through the Imperial
College PhD Scholarship Scheme.}

\tnotetext[t2]{Many thanks to Imperial College Department of Mathematics for letting
me use their computign cluster for obtaining the memory and timing
resutts reported here.}

\author[kg]{Krishnakumar Gopalakrishnan\fnref{fn1} \corref{cor1}}

\ead{krishnakumar@imperial.ac.uk}

\author[tz]{Teng Zhang\fnref{fn2}}

\ead{t.zhang@imperial.ac.uk}

\author[gjo]{Gregory J. Offer\fnref{fn3}\corref{cor2}}

\ead{gregory.offer@imperial.ac.uk}

\fntext[fn1]{Ph.D. Student, Dept. of Mechanical Engineering, Imperial College
London.}

\fntext[fn2]{Research Associate, Dept. of Mechanical Engineering, Imperial College
London.}

\fntext[fn3]{Sr. Lecturer, Dept. of Mechanical Engineering, Imperial College London.}

\cortext[cor1]{Corresponding author}

\cortext[cor2]{Principal corresponding author}

\address[icaddress]{Imperial College London, South Kensington, London SW7 2AZ United
Kingdom }
\begin{abstract}
Research into Reduced-Order Models (ROM) for lithium-ion batteries
is motivated by need for a real-time embedded model possesing the
accuracy of physics-based models, yet retaining the computational
simplicity of equivalent-circuit models. An attractive approach was
proposed by Lee et al~\citep{LeeChemistruckPlett2012} using a technique
known as Discrete-time-Realization Algorithm (DRA)~\citep{LeeChemistruckPlett2012a}.
The ROM thus obtained in standard state-space representation can be
simulated to obtain the evolution of electrochemical variables of
the standard porous-electrode Li-ion battery model~\citep{DoyleFullerNewman1993,FullerDoyleNewman1994}.
An unresolved issue of this approach is the high computation requirement
associated with the DRA, which needs to be repeated multiple times
for various SOCs and temperatures.

In this paper, we analyse the computational bottleneck in the existing
DRA and propose a significant improvement to the modelling procedure.
Our analysis reveals that the Singular Value Decomposition (SVD) of
the large Block-Hankel matrix of the system\textquoteright s Markov
parameters is a key inefficient step. A fast computational approach
is presented that significantly reduces memory usage and CPU operation
count by bypassing the redundant Block-Hankel matrix formation step.
Comparisons with existing DRA method highlight the significant reduction
in computation time and memory usage as well as improved modelling
accuracy of electrochemical quantities afforded by this new method.\end{abstract}
\begin{keyword}
Discrete-Time-Realization Algorithm (DRA) \sep Singular Value Decomposition
(SVD) \sep Doyle-Fuller-Newman Model \sep Li-ion Batteries \sep
Reduced Order Modelling
\end{keyword}

\end{frontmatter}{}


\section{Introduction}

In recent years. tightening emissions regulations for various industrial
sectors have forced a renews interest in renewable energy sources{[}cite{]}.
The demand for clean energy has led the automotive, utilities and
consumer electronics industries to develop advanced methods of storing
energy{[}cite{]}. Li-ion batteries are seen as key enablers in this
quest {[}cite{]} ; however, with this explosion in energy storage
requirements comes a stricter demand for cell longevity, performance,
and adhesion to safety requirements {[}cite{]}. Lithium-ion cells
have several advantages over other cell compositions including high
energy density, extended lifecycle, low internal resistance, low self-
discharge, long cycle life, fast charge and discharge cycles {[}cite{]}
making it no surprise that nearly all modern consumer electronics
and electric vehicle (EV) manufacturers employ this technology to
varying degrees in their product portfolio.

Ever-tightening emissions regulations have led the automotive and
utilities industries to develop advanced energy storage technologies{[}cite{]}.
Cost effective lithium-ion batteries (LIBs) are seen as a key enabler
in this quest due to their high energy and power densities {[}cite{]}.
However, mainstream adoption of LIBs in high-power applications such
as electric vehicles is limited by strict requirements for battery
cycle-life, performance, and safety {[}cite{]}.

These can all be improved
through better battery management, but this is reliant upon accurate
state and parameter estimation, as the only states measurable are
typically voltage, current \& temperature. For example state-of-charge
(SOC) cannot be measured directly but must be inferred from these
measurements. Accurate physical models of the cell enable these parameters
to be estimated more accurately and enable more advanced control strategies
to be deployed {[}cite{]}. These models must therefore be capable
of being embedded in a battery management systems (BMS) in various
applications ranging from portable electronics to automotive. Most
models have the primary intent of accurately estimating the cell\textquoteright s
open circuit voltage and state-of-charge; more advanced models enable
physical parameters that could affect the health of the battery to
be estimated. The literature on Li-ion battery modeling can be generally
classified into two broad approaches : (1) empirical equivalent-circuit
models, and (b) detailed physics-based models


Through accurate model representations of the electrochemical behavior
of the cell, advanced control strategies can be deployed to tackle
these challenges{[}cite{]}. With safety and performance being of utmost
concern, extra efforts have been made to construct accurate models
to describe the physical behavior of the cell {[}cite{]}.Modern demand
for increased performance, operating lifecycle and safety of batteries
has led to sophisticated modeling strategies. These models govern
the operation of Battery Management Systems (BMS) in various applications
ranging from portable electronics to automotive. Most models have
the primary intent of accurately estimating the cell\textquoteright s
voltage and state-of-charge;more advanced models give key insight
into physical parameters that could affect the health of the battery.
The literature on Li-ion battery modelling can be generally classified
into two broad approaches : (1) Empirical/Ad-hoc equivalent circuit
models and (b) Detailed Physics-Based models based upon first principles.However,
these two approaches are generally at loggerheads with each other
in terms of computational complexity as discussed below.

Equivalent circuit models employ circuit elements like voltage sources,
resistors and capacitors to model the general behavior of batteries.
The parameters of the circuit can be identified using numerical optimization
methods {[}cite{]} or through Electrochemical Impedance Spectroscopy
{[}cite{]}.
These circuit elements are typically parameterized at different current,
temperature, and state-of-charge (SOC) in the form of look-up tables
by fitting the model against measured charge and discharge curves.
The open-circuit voltage and capacity of the battery are
usually determined by measuring the terminal voltage and integrating
the applied current during a very slow discharge test (eg. at a C/30
rate). Using the equivalent circuit model, the cell\textquoteright s
state of charge (SOC) can be calculated using two simple methods using
discharge test data -- a) the manufacturer-specified OCV-SOC lookup
table and b) coulomb counting {[}cite{]}. Both methods are computationally
amenable for small-scale embedded applications like consumer electronics;
however, neither one is robust for modern performance demands imposed
by vehicular applications. More advanced methods which employ these
equivalent circuit models, such as nonlinear Kalman filtering, produce
very good robust estimates {[}9{]}. The usefulness of the ECM models
is limited by the fact that their parameters are derived essentially
by a curve-fitting process using training data. Since they are not
based on any physical phenomena, their ability to predict cell behavior
is extremely poor especially when applied with current profiles outside
the training realm.
Another important disadvantage
of equivalent circuit models is that they do not allow physical insights
into the internal states of the cell.



Physics-based models employ governing equations that construct an
accurate realization of the behavior of the system based on first
principles of electrochemical thermodynamics and kinetics. Doyle,
Fuller, and Newman {[}cite{]} developed a porous electrode model to
describe the cells\textquoteright{} internal variables like solid
and electrolyte potential, solid and electrolyte concentrations, and
lithium molar flux density, respectively. The fundamental advantage
to this modelling approach is that the prediction of the internal
variables can be obtained for arbitrary current profiles, whereas
the error of the equivalent circuit models is very high when current
profiles outside the model\textquoteright s training realm is applied.
Also, direct estimation of state-of-charge and cell-capacity is obtained
using the Physics-based model {[}cite{]}. The difficulty with the
physics based modelling approach is to obtain the values of all the
physical, geometric, electrochemical, thermal and kinetic parameters
of the cells. Usually, these parameters are trade secrets of various
cell manufacturers, and varies due to production spread.

However this only has to be done once for a particular cell. It is
common practice to rely on published data for estimating certain parameters
of the cell that do not depend on physical construction, especially
for those that remain universally true for a particular cell chemistry.
Only a limited
number of cell parameters can be obtained directly from laboratory
experiments. Hence, some sort of system identification method needs
to be employed for extrapolating other cell parameters. Also, it is
a common practice to rely on published data for estimating certain
parameters of the cell that do not depend on physical construction,
especially for those that remain universally true for a particular
Li-ion family of cell chemistry. The disadvantage of physics-based
models is that their simulation is time-consuming, requiring sophisticated
multi-physics PDE solvers and hence not typically suitable for embedded
applications. However, for high performance applications like automotive
battery management systems where the state-of-health monitoring is
crcuial, there is an overwhelming demand for the insight into the
internal cell variables.Thus, applying various model order reduction
technqiues are seen a key enabler in porting the predictive powers
of the physics-based model into a real-time microprocessor.

Research into reduced-order models is thus motivated by the pressing
need for a real-time embedded model with accuracy properties of the full-order
physics based models but possessing the computational simplicity of
equivalent-circuit models. A number of approaches to reduce the computational
complexity of the physics-based models have been explored in literature
{[}cite{]}, of which the two most common are single particle models
and impedance based models. The single-particle models are the simplest
of all approaches, modeling each electrode as a single solid particle,
while ignoring the variations of electrolyte concentration and potential
{[}cite{]}. They perform well for lower current inputs, however, the
outputs of these models diverge dramatically at higher C-rates{[}cite{]}.
The diffusion of Lithium in the solid being the rate-limiting step
has been the focus of many model order reduction efforts by circumventing
the need for using the PDE. Rahn and Wang (cite) have proposed using
the Pade' approximation method to model solid diffusion by truncating
the response to a desired order. The high-frequency response of this
model does not match experimental results and hence, deemed to be
of a limited value in automotive applications with rapid acceleration
and braking. A Lagrangian-like integral method was also proposed to
deal with electrolyte and solid-state diffusions, which perform well
only at low C-rates.

Impedance-based reduced order modelling approaches
are a recent evolution and were pioneered by Dr. Smith {[}cite{]}.
This approach is based on transforming the physical equations to the
Laplace domain, and then deriving linearized transfer functions for
the cell's internal variables. Markov parameters of these transfer
functions are computed numerically and finally a reduced set of poles
are used to approximate the system using techniques from linear control
theory. The significant advantage of this approachl is that it computes
only those cell-variables at particular locations of interest within
the cell geometry. This approach sharply contrasts with other model
reduction approaches which aim to minimize the order of coupled PDEs,
but still require the numerical solver to solve for all time points
and spatial nodes defined by the meshing routine. However, Dr. Smith\textquoteright s
model was limited in use since the electrolyte potentials and concentrations
were solved through finite-element method and not through simple transfer
functions. Hence, the overall computation/simulation time was no better
than existing reduced-order models obtained by other competing model
order reduction strategies.However, this was the first approach to
successfully derive a linearized transfer functions for electrochemical
variables of the pseudo-2D porous-electrode model

Dr. Lee {[}cite{]} extended the work of Dr. Smith and solved for the
electrolyte concentration and potential by applying Sturm-Louisville
theory to arrive at a multi-modal EigenFunction solution for these
electrolyte variables. Furthermore, Dr. Lee proposed a numerical method
known as Discrete-time-Realization Algorithm (DRA) that retains the
physical character of the original equations until the very last step
when the governing matrices describing the system dynamics are generated,
yielding a one-dimensional discrete-time state-space reduced-order-model
(ROM) of an entire Lithium-ion battery dynamics based upon fundamental
physical principles. The reduced order model thus obtained could then
be used to obtain the time-evolution of all the internal electrochemical
quantities of a standard porous-electrode model. In particular, as
an illustrative application, the reaction flux, solid and electrolyte
lithium concentration, the solid and electrolyte potentials in the
anode and cathode at the respective domain boundaries were studied.
The cell voltage was obtained through linear combinations of the time-domain
variables with suitable non-linear corrections.The primary advantage
of this model order reduction process is that non-linear optimization
is entirely avoided, yielding an optimal, yet deterministic method
for selection of the system order. This seminal work is a first of
its kind that is amenable to implementing real-time controls for an
entire cell without relying upon empirical ad-hoc modelling constructs
like equivalent circuits.


An unresolved issue of Lee\textquoteright s reduced-order modelling
approach is the high computation requirement associated with DRA,
which has to be performed multiple times to identify cell parameters
at various SOC and temperatures (cite book \& thesis). This bottleneck
arises from the need to form large Block-Hankel matrices of the Markov
parameters in memory, which is then suitably factorized by a Singular
Value Decomposition (SVD) step which is computationally expensive.In
this paper, we analyse the computational bottleneck in the DRA and
propose a significant improvement to the DRA procedure. In Section
2, analysis of a key step in the DRA, ie. the Singular Value Decomposition
of a block-Hankel matrix (for choosing the model order) is performed
(bottleneck 1). An analytical formulation of the massive computing
requirements (storage and floating point operation counts) for replicating
the Lee\textquoteright s model (cite) is given. Redundancies and inefficiencies
in this step are enumerated, therefore deeming the computational requirements
as unnecessary. In Section 3, a fast computational approach is presented
that significantly reduces both the memory and the floating-point
operation count of the CPU. In Section 4, the results arrived at by
applying the algorithms of section 2 are summarized and compared with
the existing DRA method. Furthermore, we compare and contrast the
much smaller computational requirements of our proposed method with
the existing DRA code for modelling the cell behavior.We conclude
by showing that the existing Discrete-Time-Realization (DRA) algorithm
can be significantly speeded up by our proposed methodology.

(Teng: Pls edit this paragraph, Im just throwing in the story) An
unresolved issue of Lee\textquoteright s reduced-order model is the
high computation requirement associated with DRA, which has to be
performed multiple times to identify cell parameters at various SOC
and temperatures (cite book \& thesis). This computation bottleneck
primarily arises from the need to form large block-Hankel matrices
of the Markov parameters, which is then factorized by the computationally
intensive SVD step. The high computation requirement of the SVD practically
requires the Markov parameters for the slow system dynamics, i.e.
lithium diffusion in solid particles, to be truncated which therefore
affects model accuracy. As was point out by Plett (cite book), \textquoteright \dots .
long impulse response\dots large Hanekl\dots{} makes to SVD intractable\dots \textquoteright .


In this paper, we analyse the computational bottlenecks in the existing
modelling process and propose a significant improvement to the DRA
procedure. This paper is organized as follows. In Section 2, analysis
of a key step in the DRA, ie. the Singular Value Decomposition of
a block-Hankel matrix (for choosing the model order) is performed
(bottleneck 1). An analytical formulation of the massive computing
requirements (storage and floating point operation counts) for replicating
the model in Dr. Lee's paper (cite) is given. Redundancies and inefficiencies
in this step are enumerated, therby deeming the computational requirements
as unnecessary. Furthermore, another computationally demanding step
in the DRA, viz. the linear algebra operation for the computation
of the system dynamics matrix A\_hat is identified (bottleneck 2).
In Section 3, a fast computational approach using powerful algorithms
is presented that slashes down both the memory and the floating point
operation count of the CPU for bottleneck 1. The same code is elegantly
reused to arrive at a solution for bottleneck 2, thereby promoting
modularity. In Section 4, the results arrived at by applying the algorithms
of section 2 are presented, by comparing them to key internal variables
from the existing DRA method. Furthermore, we compare and contrast
the much smaller computational requirements of our proposed method
with the existing DRA code for modelling the cell behavior. We show
that the existing Discrete-Time-Realization (DRA) algorithm can be
significantly speeded up by our proposed methodology.

\section{Analysis of the Computational Bottlenecks of Discrete-Time Realization
Algorithm (DRA)}

The Reduced Order Model (ROM) obtained by Dr. Lee is based upon the
thermodynamic and kinetic equations of the one-dimensional volume-averaged
model first proposed by Doyle, Fuller and Newman (cite). The overall
modelling procedure is summarized in Figure 1. First, the model equations
are linearized about an operating point and closed-form Laplace-domain
transcendental transfer functions of all the internal cell variables(phi\_s,phi\_e,c\_s,c\_e
\& j at different cell locations)are derived using the applied current
to the cell as input. The transfer functions in (cite) are summarized
in Appendix I. The authors proposed a novel Discrete-time-Realization
algorithm (DRA) in (DRA\_citation) to transform these transcendental
transfer functions to equations in standard state-space representation.
The steps involved in the Discrete-Time Realization Algorithm (DRA)
is summarized in the block diagram (Figure 2). At the heart of this
method is the classical subspace identification method known as Ho-Kalman
algorithm (cite 2 papers) (visualized in Figure 3). A key step in
the model order reduction process is the Singular Value Decomposition
of the Block-Hankel matrix formed by the Markov parameters (unit-pulse
responses) of the battery transfer functions. In the illustrative
example provided by Dr. Lee, there are 28 transfer functions, with
applied current as the input, ie. we have a Single input Multiple
Output System (SIMO), the Markov parameters of which is collected
into a Block-Hankel matrix as shown in Figure x. Each Block element
in the Hankel matrix is a column vector comprising of the Markov parameters
at every time-step. Singular Value Decomposition (SVD) is performed
on this Block-Hankel matrix and plotted as a visual aid to provide
an insight into the system order. A detailed analysis of this procedure
reveals certain weaknesses, issuesand inefficiencies in this SVD computation
step as discusses below.

\subsection{Size of the Block-Hankel Matrix}

The SVD computation can become intractable if the Hankel matrix becomes
very large. For Li-ion battery modelling, this happens due to the
following.
\begin{enumerate}
\item For a desired duration of markov-parameter recording for the SIMO
system, if the model's sampling frequency is increased, the emulation
frequency F1 has to be proportionately increased for the interpolation
in step 3 to be accurate. This requires that the total number of time-samples
for each Markov parameter (N) to be scaled proportionately to capture
the duration of the unit-pulse-response. However, the number of entries
in the Hankel matrix increases as per a quadratic law.
increases quadratically with N.
\item The recorded sample size for each Markov parameter, N, could also
become large if the unit-pulse-response of just one of the transfer
functions of the SIMO system decays very slowly. In Li-ion batteries,
diffusion within the solid particle is typically the slowest process.
In the case of the cell modelled by Lee et al, the Markov parameters
of the surface concentration of Li adjacent to the positive current
collector require approximately 8000 (16000) samples before reducing
to an appreciably low value, as shown in figure x.
\item For a battery modelling problem consisting of multiple transfer functions
(28 in this case), the number of entries in the Hankel matrix also
scales linearly with number of transfer functions. Thus, if more transfer
functions (say, concentrations and potentials at different locations
in the cell) need to be modelled, then the size of the Block-Hankel
matrix increases correspondingly.
\end{enumerate}
Combining both the effects above, if x transfer functions are to be
modelled and N samples of markov parameters are to be captured for
the duration of interest, the size of the Block-Hankel matrix would
be
\[
Size(H)\sim O(xN^{2})
\]
 The size of the Hankel matrix has a significant computational impact
as described in the following sections.

\subsubsection{Effect on Computational Demand}
Considering the above effects combined, if $x$ transfer functions
are to be modelled and $N$ time-samples of each markov parameter
are to be captured, the size of the Block-Hankel matrix shall become
\begin{equation}
Size(H)\sim O(xN^{2})\label{eq:}
\end{equation}
 The large size of the Block-Hankel matrix has a significant computational
impact as shown in Sections~\ref{sub:Traditional-DRA--Memory} and
\ref{sub:Traditional-DRA--CPU}.

If the unit-pulse-response of just any one of the transfer functions
of the SIMO system does not die down to zero in a reasonable duration,
the recorded sample size for each Markov parameter, N becomes very
large. In Li-ion batteries, diffusion within the solid particle is
considered to be the slowest i.e.rate-determining step. In the case
of the cell modelled by Dr. Lee, the Markov parameters of the surface
concentration of Li next to the positive current collector dies out
very slow as shown in figure x.

\subsubsection*{Analysis of Memory (RAM) Requirements for computing SVD}

Dr. Lee chose to use 8000 samples for his reduced order model with
a sampling interval of 1 second to allow settling of the solid surface
concentration to an acceptably low magnitude. The size of the Block-Hankel
matrix thus formed is 224000 x 8000, ie. $1.792x10^{9}$entries. Using double-precision arithmetic
(4 bytes on most computer architecture), the storage requirement for
this Block-hankel matrix can be estimated as13.35 GB.

However, as seen in the unit-pulse-response (earlier figure), the
Markov parameter does not quite die down to zero.
diminsh to zero. (Diffusion being a $t^{1/2}$ process, it would require
an infinite number of poles and zeros to capture this system as highlighted
in Bode). Thus, for theoretical accuracy, infinite number of samples
are required.With practical considerations for implementation in a
digital computer, following IEEE floating point notation, it is only
need to capture until the samples are within an order of the machine-epsilon.
Truncating at 16000 (32000) samples would require about 27 GB RAM
for holding the Block-Hankel matrix.
Recording the Markov
parameters till 16000 seconds would require about 27GB RAM for storage.Furthermore,
after computing the SVD, three more large matrices $U,Vand\Sigma$of
the same size are formed in memory. Thus, running the algorithm necessitates
a requirement of 26.68 GB of free memory. For calculating the system
dynamics matrix A\_hat, the row-shifted Hankel matrix (symbol here)
is also held in memory (although to be fair, only the first n number
of columns of U, V and Sigma are retained before this computation,
and the original unshifted Hankel matrix can be cleared to free up
RAM) is further compounded by the necessity of more higher frequency
models. For using the reduced order model successfully in high-dynamic
load drive-cycles (like cite e.g.), it requires that the model be
valid at least until the highest operating frequency of the drive-cycle.
Assuming no computational errors, the sampling frequency required
to perfectly capture all the dynamics will be at least twice of this
nyquist frequency. For the UDDS drive-cycle, the highest frequency
content of the input current is. Thus, if the reduced order model
(ROM) running at 0.5s (verify) sample time is to be derived, then
32000 time-samples are needed for each Markov parameter for capturing
the pulse duration until 16000 seconds. Analysis of the memory calculation
yields $4x28x(32000)^{2}$bytes = 114688000000 byes = 106.8 GB of
free memory for holding the Hankel matrix alone, and a total of 427
GB of free memory for holding the resulting output matrices. Intermediate
memory storage during the SVD computation and the baseline operating
memory are not taken into account in this calculation. The problem
is further compounded by having a battery model wherein the smaller
diffusion coefficients are smaller than those studied here. The Markov
parameters of the solid surface concentration transfer function shall
now decay to zero further slowly, necessitating a very large number
of samples to be captured. Furthermore,obtaining the battery model
at different SOCs and temperature would mean that we need to re-linearize
the original PDEs under those conditions and obtain the corresponding
transfer functions, markov parameters and Block-Hankel matrices. These
large matrices have to be loaded onto the memory for every SOC and
temperature run, thereby significantly slowing down the modelling
procedure. This analysis reveals that doubling the number of transfer
functions doubles the size of the Block-Hankel matrix.


Edit this - Furthermore, after computing the SVD, three more similar-sized
matrices $U$,$V$and \textgreek{S} are formed in memory, necessitating
a requirement of 26.7 GB of free memory - edit this). but the intermediate
operational memory requirement for SVD is the highest. The in-operando
memory requirement is the highest. S is n{*}n, U is (2000{*}28{*}10xn),
V is (28{*}n).


The memory requirement is further compounded by the necessity of generating
high sample-rate discrete-time models. For using the reduced order
model successfully in high-dynamic load drive-cycles (like cite e.g.),
it requires that the model be valid at-least until the highest operating
frequency of the drive-cycle. For the UDDS drive-cycle (cite), the
highest frequency content of the input current is XXX. Thus, if the
reduced order model running at 0.5s (verify) sample time is to be
derived, then 32000 samples for each transfer function is needed for
capturing the unit-pulse response until 16000 seconds. This implies
that106.8 GB of free memory is needed for holding just the Block-Hankel
matrix, and a total of 427 GB of free memory is needed for holding
the resulting output matrices of the SVD. Furthermore, obtaining the
battery model at different SOCs and temperature would mean the necessity
to re-linearize the original PDEs under those conditions and obtain
the corresponding transfer functions, markov parameters and Block-Hankel
matrices. These large matrices have to be loaded onto the memory for
every SOC and temperature run, thereby significantly slowing down
the modelling procedure.

Considering the above effects combined, if $x$ transfer functions
are to be modelled and $N$ time-samples of each markov parameter
are to be captured, the size of the Block-Hankel matrix shall become
\begin{equation}
Size(H)\sim O(xN^{2})\label{eq:}
\end{equation}
 The large size of the Block-Hankel matrix has a significant computational
impact as shown in Sections~\ref{sub:Traditional-DRA--Memory} and
\ref{sub:Traditional-DRA--CPU}.


\subsubsection{Traditional DRA -Memory (RAM) Requirements\label{sub:Traditional-DRA--Memory}}

Lee et al used 16000 samples for the ROM workflow with a sampling
interval of 1 second. This allows sufficient time for the Markov parameters
of the solid surface concentration to settle to an acceptably low
magnitude. The size of the Block-Hankel matrix thus formed consists
of $224000x8000=1.79x10^{9}$ entries. Using double-precision arithmetic,
the storage requirement for this Block-hankel matrix alone can be
estimated to be 27 GB.

However, as seen in Figure~\ref{f:markov_cse_pos}, the Markov parameters
of the solid surface concentration does not diminsh exactly to zero.
Diffusion being a $t^{1/2}$process, an infinite number of poles and
zeros is required to capture the full dynamics of this system. This
is highlighted by the -10 dB/decade slope of the Bode Magnitude plot
(Figure~\ref{f:bode}) of the Jacobsen-West transfer function~\citep{JacobsenWest1995}
describing solid diffusion.Thus, infinite number of Markov parameter
samples are required to capture the system dynamics accurately. With
practical considerations for implementation in a digital computer,
following IEEE floating point notation, it is only need to capture
the samples until their magnitude is within order of machine-epsilon.

\begin{figure}[h]
\input{bode.tex}
\caption{Solid Diffusion Transfer Function (Positive Electrode)}
\label{f:bode}
\end{figure}

\subsubsection*{Analysis of CPU Operation Count for computing SVD}

The most widely used numerical algorithm for computing the full Singular
Value Decomposition (SVD) of a general dense matrix $A\epsilon\mathcal{R}^{mxn},m\geq n$
is the Golub-Kahan-Reinsch method (cite). The first stage involves
reducing the dense matrix $A\epsilon\mathcal{R}^{mxn},$into an upper
bidiagonal matrix $B\epsilon\mathcal{R}^{mxn}$by the standard bidiagonalisation
algorithm using Householder reflections. This algorithm requires $4mn^{2}-4n^{3}/3$
operations. However, in the case of battery modelling problem, we
always have a 'tall' Block-Hankel matrix, since the number of time-samples
of the unit-pulse response collected is far greater than the number
of transfer functions being modelled., i.e. $m\gg n$. Furthermore,
there exists an efficient algorithm for this step if $m\geq5n/3$
known as $\mathcal{R}$-Bidiagonalisation (cite), which first reduces
the matrix $A\epsilon\mathcal{R}^{mxn}$ to a triangular matrix using
the QR\LyXFourPerEmSpace decomposition and then employing Householder
reflections to further reduce the matrix to bidiagonal form. Again,
this condition of $m\geq5n/3$ is always satisfied for the Block-Hankel
matrix formed by the markov parameters of a vector of transfer functions
of a typical battery. The operation count for the $\mathcal{R}$-Bidiagonalisation
step is $2mn^{2}+2n^{3}$. The second stage computes the SVD of the
upper bidiagonal matrix $B\epsilon\mathcal{R}^{mxn}$ using an iterative
procedure (Demmel-Kahan method) upto a certain precision, typically
the machine epsilon (cite). The second stage takes $\mathcal{O}(n)$iterations,
each costing $\mathcal{O}(n)$ floating point operations.This is typically
done by a variant of the QR\LyXFourPerEmSpace algorithm for the computation
of eigenvalues, which was first described by Golub\LyXFourPerEmSpace \&\LyXFourPerEmSpace Kahan\LyXFourPerEmSpace (1965).
The LAPACK subroutine DBDSQR implements this iterative method, with
some modifications to cover the case where the singular values are
very small (Demmel\LyXFourPerEmSpace \&\LyXFourPerEmSpace Kahan\LyXFourPerEmSpace 1990).Together
with a first step using Householder reflections and, if appropriate,
QR decomposition, this forms the DGESVD routine for the computation
of the singular value decomposition for a real rectangular matrix.
Other variants of this routine are available including DGESDD (which
uses a divide-and-conquer algorithm for the bidiagonal SVD) and ZGESDD
(for SVD of a complex matrix). The DSESVD algorithm, originally implemented
in LAPACK is numerically stable and versitile has ported onto many
numerical computation packages (MATLAB,GNU Octave, Scilab) and numerical
libraries (NAG, Intel MKL) that this is the de-facto SVD algorithm
nowadays . The MATLAB implementation svd is also based upon this.

If $\mathcal{R}$-Bidiagonalisation for stage I of the SVD computation,
then the overall process is referred to as $\mathcal{R}-SVD.,$which
is the fastest standard algorithm for the full-SVD computation for
this battery modelling problem at hand. The exact analysis of the
overall operation count for computing the singular values and singular
vectors using the $\mathcal{R}-SVD$ method was analysed in (cite)
and is shown to be $4m^{2}n+22n^{3}$. For a Block-Hankel matrix constructed
from the Markov parameters of $x$ transfer functions and $N$ time-samples
of pulse-response data for each transfer functions, we have $m=xN$
(rows) and $n=$N (columns)

\[
ExactOperationCount=4(xN)^{2}N+22N^{3}=2N^{3}(11+2x^{2})
\]

For the battery modelling task at hand, consisting of 28 transfer
functions, Markov parameters are collected for a duration of 8000
seconds using a sampling interval of 1second. Thus the operation count
of SVD is approximately $O(8000^{3})=1.6169e+15floating$point operations.
On the latest 6th generation Quad-Core Intel Core i7-6700K desktop
processor (Skylake architecture, 4.2GHz, 8M cache, released August
2015) capable of 81.28 GFlops (Whetstone Double-Float Benchmark),
even with implicit paralleization,this SVD operation procedure would
theoretically take 1.9893e+04 seconds = 331.5486 minutes = 5.525 hours.
To obtain the reduced-order battery model for a wide SOCs and temperatures
we need to re-lineare the original PDE equations for these conditions
(cite). This implies that the SVD has to be re-computed for the new
set of . For 20 SOC points from 0 to 100\% and for a temperature range
from -10C to 40C at increments of 10C, there are a total of 120 operating
points, which means that 663 hours of operation on a high-end machine.
The SVD computation time scales up as the cube of the chosen number
of time-samples of the unit pulse-response, rendering calculations
for anything more than 8000 samples virtually intractable, which would
automatically preclude choosing a lower sampling frequency of the
model and inherently prevents capturing the dynamics of drive-cyles
above 2Hz (for this specific case under consideration with 1 second
sampling frequency). Mention about 16-core workstation and estimate
the hours of SVD operation for a single SOC and temperature. Choosing
more transfer functions to study has a quadratic increase on the number
of floating point operations. Thus doubling the number of transfer
functions being modelled will effectively require about 22 hours on
the quad-core machine and \_\_\_ hours on the 16-core workstation
for computing the SVD at a single SOC and temperature. Although a
GPU farm computation of the SVD using CUDA/OpenCL libraries can be
considered, large scale data movement quickly overwhelms the GPU pipelines.
Furthermore, even the latest NVIDIA Tesla high-end scientific computing
GPUs cannot handle the sheer amount of memory required even for a
moderately sized problem of 28 battery transfer functions and 8000
samples.

From the above discussion, the SVD computation step in the DRA procedure
can be identified as Bottleneck \#1.


An even faster methodIf $\mathcal{R}$-Bidiagonalisation is employed
for stage I of the SVD computation, then the overall process is referred
to as $\mathcal{R}$\textminus SVD and is the fastest standard algorithm
for the full-SVD computation for this battery modelling problem. The
overall operation count for computing the singular values and singular
vectors using this method was analysed in (cite) and is shown to be
$4m^{2}n+22n^{3}$. For a Block-Hankel matrix constructed from the
Markov parameters of $x$ transfer functions and $N$ time-samples
of pulse-response data for each transfer functions, we have $m=xN$
(rows) and $n=N$ (columns).
\begin{alignat*}{2}
\mathcal{R}-SVD\text{ Operation Count} & = & \,4\left(xN\right){}^{2}N+22N^{3}\\
 & = & \,2N^{3}\left(11+2x^{2}\right)
\end{alignat*}

Thus the CPU operation count scales as $\mathcal{O}(N^{3})$ with
the number of time-samples and as $\mathcal{O}(x^{2})$ with the number
of transfer functions being modelled. For the battery model in Lee
et. al consisting of 28 transfer functions, (Markov parameters collected
for 8000 (16000) seconds with a 1-second sampling interval), the operation
count is approximately $\mathcal{O}(8000^{3})=512x10^{9}$ floating
point operations.

Note: Mention that SVD can't be easily paralellized, but certain implementations,
including the MATLAB one can be multithreaded. Check but there is
a further memory penalty of copying the info to other threads ? Restrict
Math cluster has only one core. (check specs). Therefore, if multithreading
is used, computational time may go down , but memory may go yo....need
to verify all of these thigns.

\subsubsection{Summary Effect of Computational Bottlenecks}

Although the analytical framework of the reduced order model formulation
allows the user to simulate the cell-variables at any location of
interest, in practice, this capability is severely hampered by the
bottlenecks in the DRA. The real-life scenarios enumerated below highlights
the significant reduction in the general applicability of this modelling
approach..

The foregoing analysis clearly demonstrates that the memory and CPU
requirements in computing the SVD step of the DRA severely hamper
the scope and applicability of the ROM based on the current DRA algorithm.
The large memory requirement associated with the bock Hankel matrix,
in particular, also means that the model identification process is
not accessible to a large number of research groups without specialized
computing infrastructure. The computation bottleneck becomes particularly
limiting in studying the following real-life scenarios:
\begin{enumerate}
\item The linear increase in memory requirement with the number of transfer
functions quickly limits the number of transfer functions can be studied,
e.g. Studying cell-variables at other locations, that may be of interest
within the cell, e.g. in the middle of the electrode thicknesses becomes
intractable.
\item The quadratic increase in the SVD operation count with the number
of transfer functions greatly reduces the computational speed. This
inhibits a quick 'what-if' scenario analysis, e.g. monte-carlo sweep
to understand the effect of just physical parameter like the diffusion
coefficient or conductivity would require the user to wait for hours
on-end at the terminal, defeating the end gains of the model order
reduction process
\item The extensibility of the model will significantly slow down in studying
battery systems of lower diffusivity, e.g. in the case of Li-S batteries,
the precipitation step is the rate-limiting step and the Markov parameters
die down after a very long duration. This necessitates early truncation
of the Markov parameters to avoid computing bottlenecks and hence,
resulting in severe modelling errors (due to errors in the singular
values and vectors)
\item Cell-variables at other locations locations of interest within the
cell (e.g. in the middle of the electrodes or separator) might need
to be modelled in the system in addition to the 28 cell variables
studied in Lee et al. The increased number of cell variables correspond
to increased number of transfer functions, which in turn require a
linear increase in memory and quadratic increase in CPU usage.
\item Battery systems consist of systems with a mix of slow and fast internal
dynamics. The slow internal dynamics, e.g. solid phase diffusion in
Li-ion and precipitation in Li-S cells, whose Markov parameters decay
after a very long duration become a limiting factor in deriving the
model due to excessive increase in computing requirement. This necessitates
early truncation of the Markov parameters to avoid computing bottlenecks
and hence, resulting in modelling errors (due to errors in the singular
values and vectors computed)
\item High-frequency load cycles (like the NEDC? which has higher dynamics
than the UDDS results shown in Lee et. al), which necessites a correspondinly
higher sampling frequency and hence a larger $N$. cannot be studied
at all.
\item In a battery model with a different set of physical parameters (larger
particle radius, slower solid-diffusion coefficient) than that studied
in Lee et al, even the achieved accuracy levels might not be repeatable,
yielding the universal applicability of the DRA process questionable.
\end{enumerate}
The large memory requirement also means that the modelling process
is not accessible to a large number of research groups without specialized
high-memory computing infrastructure. Even with access to a computing
machine with high memory and powerful processor, the modelling process
takes hours of computation for a single SOC and temperature.Repeating
the process across various SOCs and temperatures would naturally slow
down the whole modelling procedure, thus defeating the larger goal
of the reduced order modelling process.
Even with access to a computing machine with high memory and powerful
processor, the modelling process takes hours of computation for a
single SOC and temperature.Repeating the process across various SOCs
and temperatures would naturally slow down the whole modelling procedure,
thus defeating the larger goal of the reduced order modelling process.

\section{Efficient Computation of Block-Hankel SVD}

Apart from circumventing the computing infrastructure requirement,
research into efficient SVD implementation is motivated by the following
scientific rationale.
The computational bottleneck presented here is recognized in (cite)
and the use of the Eigen Realization Algorithm (ERA) was proposed
as a means to partially mitigate the issue. which allows for a moderate
reduction in memory requirements and CPU floating-point operations.
This is done by intentionally omitting a few of the Markov parameters,
and hence deleting some of the rows and columns of the Block-Hankel
matrix, thereby reducing its size. Furthermore, the ERA algorithm
is typically intended for system identification in the case of noisy
measured data. However, for a battery modelling problem, the Markov
parameters are obtained from noise-free analytical transfer functiions.
Thus, there is no clear direction in the form of a published rigorous
method for selection of the rows and columns to be omitted.

Apart from needing computing infrastructure with a large memory to
handle the block-Hankel matrices and high-end processors to handle
the traditional full-SVD routine, research into efficient SVD implementation
is motivated by the following scientific rationale.
\begin{enumerate}
\item Markov parameters of most battery transfer functions settle to their
final steady-state fairly quickly. Thus, it is inefficient to record
the Markov parameters of these transfer functions as entries of the
Block-Hankel matrix thereby increasing its size. However, in the current
modelling architecture, in order to account for a few slow dynamics
(particularly the solid surface concentration), the markov parameters
of the entire SIMO vector of all transfer functions is fed into the
Block-Hankel matrix. This degrades the performance, especially since
accumulating more time-samples heavily influences memory requirement
in forming the Block-Hankel matrix and the operation count in computing
the SVD.
\item The Block-Hankel matrix, whose entries are simply the Markov parameters
arranged in a special way is essentially redundant information. Thus,
in theory, it is wasteful to construct this huge matrix especially
given the fact this is the primary bottleneck for the SVD. If the
SVD operation can be performed on a virtual Hankel matrix, the memory
requirements can be drastically reduced.
\item The matrix of singular values,$\Sigma$ is diagonal and thus, highly
sparse. After the full SVD (of a Hankel matrix with 8000 time-samples
and 28 data points), a 6 GB matrix of mostly zeros is constructed
in memory. Clearly, this is redundant.
\item Furthermore, performing a full SVD operation is not required for model
reduction. The transfer functions forming the battery model yield
a large number of poles with a mix of fast and slow dynamics. The
idea behind SVD computation is to reduce the order of the system and
obtain a low-order approximation. Hence, it is sufficient to compute
a truncated SVD yielding the first few significant values (i.e. an
upper-bound of desired system order decided apriori).
\item Markov parameters of most battery transfer functions (other than the
rate-limiting step, i.e. Li-diffion in solid particle) settle to their
final steady-state fairly quickly. Thus, it is inefficient to record
the Markov parameters of the entire SIMO system for the entire duration
needed to capture the slowest dynamics. the entire SIMO vector of
all transfer functions is fed into the Block-Hankel matrix. This degrades
the performance as accumulating more time-samples increases the size
of the Block-Hankel matrix leading to the memory and CPU bottlenecks
for SVD computation step as discussed in Section \ref{subsec:Effect-on-Computational-Demand}
\item The Block-Hankel matrix, whose entries are nothing but the Markov
parameters arranged in a repeating special structure is essentially
redundant information. Thus, in theory, it is wasteful to construct
this huge matrix especially given that this is the primary bottleneck
for the SVD. If the SVD operation can be performed on a virtual Hankel
matrix, the memory requirements can be drastically reduced.
\item The matrix of singular values,$\,\Sigma$ is diagonal and thus, highly
sparse. After the full SVD (of a Hankel matrix with 8000 (16000) time-samples
and 28 data points), a 6 GB matrix of mostly zeros is constructed
in memory. Clearly, this is redundant information.
\item Performing a \textit{full} SVD operation is not required for model
order reduction. The transfer functions forming the battery model
yield a large number of poles with a mix of fast and slow dynamics.
The idea behind SVD computation is to reduce the order of the system
and obtain a low-order approximation. Hence, it is sufficient to compute
a truncated SVD yielding the first few significant values (i.e. an
upper-bound of desired system order decided apriori).
\end{enumerate}
Having identified the formulation of the Block-Hankel matrix as the
origin of the computational bottleneck, we propose an improved method
of computing this specific SVD that retains the powerful physics-based
reduced order modelling based, but replacing the key bottlenecks in
the DRA with highly efficient computational algorithms.

\subsection{Fast, reduced-Memory SVD Implementation for Battery Modelling}

The DGESVD algorithm mentioned in Section 2, originally implemented
in LAPACK is a numerically stable and versitile algorithm for computing
SVD of a generic real rectangular matrix. This routine has been ported
onto many numerical computation packages (MATLAB,GNU Octave, Scilab)
and numerical libraries (NAG, Intel MKL) that this is the de-facto
SVD algorithm nowadays, and the MATLAB implementation svd is also
based upon this code. However, owing to its inherent generality, this
SVD routine does not take advantage of the special anti-diagonal symmetry
structure of the Block Hankel matrix arising in this battery modelling
problem. As mentioned in Section 2, computing the full-SVD is wasteful
in a reduced order modelling application given that only the first
few leading triplets are intended to be used. Hence, for obtainig
a reduced order model, it is desirable to impose an apriori upper
bound of a system order. Thus, the candidate SVD algorithm needs to
compute only the first few leading eigen triplets (Singular values
and corresponding singular vectors), upto the chosen system order.
Thus iterative algorithms like the Jacobi and Lanczos schemes described
in {[}45{]} can be considered for computation of the dominant singular
values of a Block-Hankel matrix. To keep the computation accessible
to the large community of battery researchers and to encourage widespread
adoption of the fast reduced order modelling, we consider only open-source
libraries available for free in the public domain. Otherwise the gains
brought about by efficient computation of SVD (i.e. using more affordable
computer hardware) would be offset by comercial licensing terms, usage
restrictions and other monetary drawbacks of using proprietary codes.
The Jacobi scheme is available in the free open-source package LAPACK
via the xGESVD routine. The implicitly restarted Lancsoz scheme is
available in the ARPACK libraries (which are in Fortran 77). The 'economy'
size SVD implementation in MATLAB (i.e. the svds function)also implements
ARPACK.

The main drawback of both these specific implementations are that
their input argument is the matrix itself whose SVD needs to be computed.
For reasons detailed in Section 2, the chosen SVD algorithm must be
able to handle the computation without actually forming the huge block-Hankel
matrix in memory. The pioneering work of Rasmunk Munk Larsson, PROPACK,
designed specially for large and sparse matrices, implemented a numericallty
stable and Lanczos SVD computation that could accept its input arguments
in the functional form rather than as matrices. The functional inputs
needed are multiplication routines for the Hankel matrix and its transpose
with an arbitrary vector. The PROPACK code is distributed under a
permissive BSD license. Furthermore, the PROPACK implementation of
Lancsoz is available as both Fortran 77 and MATLAB codes thereby widening
its reach. Finally, the PROPACK package includes special algorithms
to compensate for the numerical errors introduced in the Lanczos bidiagonalisation
and ensures orthogonality of the input and output singular vectors
by using Gram-Schmidt partial reorthogonalization scheme.

In order to use the salient feature of PROPACK, i.e. the flexibility
to supply it with a functional form of the matrix-vector multiplication
routines, the key is to use an algorithm that effectively exploits
the affine structure of the block Hankel matrix without actually forming
it in memory. Recent research conducted in a specialized time-series
analysis method known as Singular Spectrum Analysis (SSA) has yielded
efficient methods for achieving this goal. Korobeynikov (cite) proposed
an algorithm that uses the Fast Fourier Transform (FFT) for this matrix-vector
product by embedding the Markov parameters into the column vectors
of a circulant matrix. This is suitable for applications wherein the
Hankel matrix is composed of scalar entries formed by the Markov parameters
of a single input single output (SISO) transfer functon. Golyandina
and Usevich (cite) extended this to a generic 2D-case for performing
Singular Spectrum Analysis (SSA) on images, which is capable of handling
Block-Hankel matrices such as the ones formed by a Multi-Input-Multi-Output
(MIMO) system. Instead of forming the huge Block-Hankel matrix, the
algorithm works directly on the much-smaller matrix of Markov-parameters,
with rows corresponding to the battery transfer functions being modelled
and the columns corresponding to the total number of time-samples
recorded. Discuss the operational count here. Discuss the memory requirements
here.

The Golyandina-Usevich algorithm along with specific considerations
to the battery modelling problem is briefly summarised in Appendix
xx. The algorithm offers several advantages like pre-computation of
fast-fourier-transform of the Markov Parameter Matrix (MPM), and efficient
code reuse for computation of the matrix-vector product for both the
Hankel matrix and its transpose. Thus, the strategy is to use the
Golyandina-Usevich algorithm for the matrix-vector multiplication
routines and feeding them as inputs to the PROPACK codes without forming
the huge matrices in memory. The results discussed in Section \ref{sec:Results}
demonstrate the performance improvement using these routines without
any trade-off in fidelity of the model. In fact, the Reduced Order
Model's accuracy can be improved since the need for early truncation
of the Markov parameters is virtually eliminiated since there is no
need to form the Block-Hankel matrix anymore in memory. MATLAB codes
for the proposed workflow are made available as supplementary material
for download.

\subsection{Analysis of CPU Operation Count}

\subsection{Analysis of Memory Requirements}

\section{Simulation and Results\label{sec:Results} }

In this section, we demonstrate the performance improvement, viz.
improved accuracy as well as reduced computational requirements of
the modified DRA algorithm by comparing it against the original algorithm
in Lee et al. The numerical accuracy of both the original and improved
DRA in predicting the cell's internal variables is compared against
the full-order pseudo-2D porous-electrode PDE model simulated using
COMSOL Multiphysics 5.1. The cell parameters are those published by
Doyle et al. and listed in \ref{sec:Table-of-Battery}. The specifications
of the computer workstation used in these simulation is shown in Table
xx. All simulation parameters are listed in Table xx and is the same
as that reported in Lee et al. .

\begin{table}

\caption{Simulation Parameters}

\begin{tabular}{|l|c|}
\hline
Initial Cell SOC & 60\%\tabularnewline
\hline
\hline
Hankel Block Size & 8000\tabularnewline
\hline
Sample-Time of Discrete-Time model, $T_{s}$ & 1 sec\tabularnewline
\hline
Number of Electrolyte EigenModes & 5\tabularnewline
\hline
Emulation (Interpolation) Frequency, $F_{1}$ & 128 Hz\tabularnewline
\hline
Desired Number of Singular Values & 10\tabularnewline
\hline
\end{tabular}

\end{table}

For the first set of simulations, the cell input current is based
on the US Environmental Protection Agency's (EPA) Urban Dynamometer
Drive Schedule (UDDS) is shown in Figure xx. The maximum frequency
content in this input current cycle is as shown by the frequency spectrum
in Fig xx.

To highlight the increased computational requirements and reduced
accuracy of the original DRA under highly-dynamic loads, the NEDC/Hwy/Other
Suitable drive cycles. The spectrum reveals that the highest frequency
content is xx.

\begin{figure}[tbp]
\input{markov_cse_pos_zero.tex}
\caption{Time Evolution of Markov Parameters}
\label{f:diagram}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics{block_Hankel_structure.png}
\caption{Write some caption here}
\label{random}
\end{figure}

Rough ideas and words...need to edit.

Existing algorithm also uses \texttt{svds}. ``Error using svd Requested
224000x224000 (373.8GB) array exceeds maximum array size preference.
Creation of arrays greater than this limit may take a long time and
cause MATLAB to become unresponsive.''
.The numerical accuracy of both the original and improved DRA in predicting
the cell's internal variables is compared against the full-order pseudo-2D
porous-electrode PDE model simulated using COMSOL Multiphysics 5.1.

For the first set of simulations, the cell input current is based
on the US Environmental Protection Agency's (EPA) Urban Dynamometer
Drive Schedule (UDDS).


This leads to the possibility of modelling other electrochemical quantities
in the cell geometry without being hindered by memory limitations.
Furthermore, high sample-rate models to handle highly dynamic load
profiles can be deployed in future BMS applications. This also empowers
the ROM framework to tackle cells with slower dynamics or perhaps
chemistries with slowe rate-limiting reaction mechanisms.

Is of value in very large system, and the iterative cost of computing
the Lamncoz becomes valuable only when the matrix is above a certain
size. The size-trade-off on a machine with certain amount of RAM/CPU
time is also given. The real value is to reduce RMS cell voltage error
as well as error in other internal variables. As a typical case, we
can 1000 operating conditions (soc \& temp) in about 6 hours. Can
study other areas as well. - not just electrode/separator quickly
and easily without waiting for the modelling process. SVD was multithreaded.
(+/-250 MB accuracy for Hankel matrix for 8000 Block-Size, +/-25MB
for 7000 Block-Size, +/-22.6MB for 6000,+/-22MB for 5000, etc. ).
Need to get hardware info (esp. CPU info( from par20, large240 and
large500 queues.). Note: Markov computation can only be performed
in power of 2\textasciicircum n samples (because of fft calc efficiency).
The values shown ate interpolated between calc. times (also highly
dependent on the specific cell parameter values, no. of EigenModes
chosen etc...Not deterministic ???. In-memory computational RAM for
the way I am currently computing the Markov parameters, because eval
function is very very slow, perhaps it might make sense to compute
only Markov , and keep Hd evaluation separately as off-topic ...Note,
in the table below, Markov computation includes intermediate storage
for hd (anyway, regular storage for Hd has to be accounted and added
up for total memory requirements ?) ??...also think about what to
do when you show different diffusion rates). Our compiled SVD code
run as a mex function could potentially be faster. The RAM consumed
by the new SVD mainly depends on moving data around and passsing it
between subfunctions in PROPACK etc. Communication overhead. Also,
fft is memory efficient and faster on certain block-sizes etc. Computed
mem results for lansvd include circulant fft + lansvd and associated
subcalls + memory occupied by U, Sigma and V. Computation of Markov
parameters, time and memory is highly dependent on the emulation (multiplier)
frequency chosen. Of course, you can optimise a lot with respect to
sampling freq/emulation freq, truncatiion of Markov etc. ,,, but the
point is not that...the point is to do a direct comparison of old
and new methods for same set of parameetsr (for a given set) ;.....and
removal of a big bottleneck....In the current implementation, the
mem limit is imposed by no. of electrolyte eigenmodes...the problem
is really complicated...for high freq model , you need more eigenmodes,
which means more RAM usage.........not a lot in comparison...but still
.....Have to check if the same applies if I do MEX thing....Without
mex, initially limied by Markov, and then quickly becomes limited
by no. of eigenmodes for memory. MEX is verified to be much much better
for memory, but double the processing time due to communication overhead.....still
in seconds

\begin{table*}
\begin{tabular}{|>{\raggedleft}m{1cm}|>{\raggedleft}m{1cm}>{\raggedleft}m{1.6cm}rr>{\raggedleft}m{1.6cm}>{\raggedleft}m{1.6cm}>{\raggedleft}m{1.6cm}|}
\hline
\multirow{2}{1cm}{Block Size } & \multicolumn{4}{c}{RAM Usage (MB)} & \multicolumn{3}{c|}{CPU Time (sec)}\tabularnewline
\cline{2-8}
 & Compute Markov & Hankel Formation & SVD & \multicolumn{1}{r|}{Total} & Hankel Formation & SVD & Total for DRA portion\tabularnewline
\hline
500 & 0.21 & 53.41 & 265.10 & 318.72 & 0.029 & 27.78 & 27.81\tabularnewline
1000 & 0.43 & 213.62 & 1107.71 & 1321.76 & 0.11 & 48.33 & 48.44\tabularnewline
2000 & 0.85 & 854.49 & 6092.96 & 6948.30 & 0.45 & 131.18 & 131.63\tabularnewline
3000 & 1.28 & 1922.60 & 13774.04 & 15697.92 & 1.01 & 407.39 & 408.40\tabularnewline
4000 & 1.71 & 3418.00 & 24590.48 & 28010.19 & 2.26 & 640.62 & 642.88\tabularnewline
5000 & 2.14 & 5340.60 & 38668.11 & 44010.85 & 3.51 & 908.12 & 911.63\tabularnewline
6000 & 2.56 & 7690.40 & 56695.77 & 64388.73 & 5.11 & 1118.42 & 1123.53\tabularnewline
7000 & 2.99 & 10468.00 & 77267.02 & 87738.01 & 6.86 & 1918.06 & 1924.92\tabularnewline
8000 & 3.42 & 13672.00 & 100282.13 & 113957.55 & 9.59 & 1899.67 & 1909.26\tabularnewline
9000 & 3.85 & 17303.00 &  &  & 11.48 & 2876.86 & 2888.34\tabularnewline
10000 & 4.27 & 21362.30 &  &  & 14.30 & 3781.26 & 3795.56\tabularnewline
11000 & 4.70 & 25848.39 &  &  & 17.35 & 5224.82 & 5242.17\tabularnewline
12000 & 5.13 & 30761.72 &  &  & 21.62 & 5561.09 & 5582.71\tabularnewline
13000 & 5.55 & 36102.29 &  &  & 24.20 & 5728.16 & 5752.36\tabularnewline
14000 & 5.98 & 41870.12 &  &  & 28.55 & 6692.76 & 6721.31\tabularnewline
15000 & 6.41 & 48065.19 &  &  & 33.41 & 6467.43 & 6500.84\tabularnewline
16000 & 6.84 & 54687.50 &  &  & 38.71 & 9963.52 & 10002.23\tabularnewline
\hline
\end{tabular}

\caption{Computational Requirements of Traditional DRA}
\end{table*}

\begin{table}
\begin{tabular}{|>{\raggedleft}m{1cm}>{\raggedleft}m{1.5cm}>{\raggedleft}m{1cm}>{\raggedleft}m{1cm}c|}
\hline
\multirow{2}{1cm}{Block Size} & \multicolumn{2}{c}{RAM Usage (MB)} &  & \multirow{2}{*}{CPU Time (sec)}\tabularnewline
\cline{2-4}
 & Hd+Markov Computation & Markov Only & SVD & \tabularnewline
\hline
500 & 218.13 & 0.21 & Too many & \tabularnewline
1000 &        471.53 & 0.43 & to & \tabularnewline
2000 &        978.32 & 0.85 & fit in & \tabularnewline
3000 &        1485.10 & 1.28 & this table & \tabularnewline
4000 &        1991.90 & 1.71 &  & \tabularnewline
5000 &        2498.70 & 2.14 &  & \tabularnewline
6000 &        3005.50 & 2.56 &  & \tabularnewline
7000 &        3512.30 & 2.99 &  & \tabularnewline
8000 &         4019.00 & 3.42 &  & \tabularnewline
9000 &        4525.80 & 3.85 &  & \tabularnewline
10000 &        5032.60 & 4.27 &  & \tabularnewline
11000 &        5539.40 & 4.70 &  & \tabularnewline
12000 &        6046.20 & 5.13 &  & \tabularnewline
13000 &          6553.00 & 5.55 &  & \tabularnewline
14000 &        7059.80 & 5.98 &  & \tabularnewline
15000 &        7566.60 & 6.41 &  & \tabularnewline
16000 &     8580.10 & 6.84 &  & \tabularnewline
\hline
\end{tabular}

\caption{}

\end{table}

\begin{figure}
\centering
\input{old_dra_svd_ram.tex}
\caption{Memory Usage of Existing DRA Method}
\label{f:2}
\end{figure}

\begin{figure}
\centering
\input{svd_compare.tex}
\caption{Note that the first singular value from Plett's paper is diff}
\label{f:3}
\end{figure}

For accuracy comparison and trunction, please plot comparison plots
of the following longer truncation vs. early trunction

1. Time-domain voltage

2. all other electrochemical variables

Please explain the slowest decaying Markov parameter and plot i the
residue by zooming in. (maybe 4 plots ?)

\section{Nomenclature}

\section{References}

\appendix

\section{Table of Battery Parameters\label{sec:Table-of-Battery} }

\section{Golyandina-Usevich Algorithm}

\section{Basic Lanczos Scheme}

\section{Symbolic Transfer Functions Modelled}

\section{Specifications of Workstation Used\label{sec:Specifications-of-Workstation}}
\end{document}
