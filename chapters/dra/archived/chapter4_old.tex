% -*- root: ../main.tex -*-
%!TEX root = ../main.tex
% this file is called up by main.tex
% content in this file will be fed into the main document
% vim:textwidth=80 fo=cqt

\chapter{Computational Analysis and Numerical Reformulation of the \glsfmtshort{dra}}\label{ch:improveddra}
% \chapter{Analysis of the \glsfmtlong{dra} and Performance Boost through Numerical Reformulation}\label{ch:improveddra}
% \chapter{Computational Bottleneck Analysis of the \glsfmtshort{dra} and its Mitigation through Numerical Reformulations}\label{ch:improveddra}
\startcontents[chapters]
\printcontents[chapters]{}{1}{\setcounter{tocdepth}{1}}

\bigskip

\capolettera{T}{his} chapter presents  an analysis and critical  evaluation of a
computational bottleneck present  in a popular \gls{rom}  framework and proposes
an  alternative numerical  reformulation  to  mitigate it\footnote{This  chapter
is  based  on the  journal  publication  --- \fullcite{Gopalakrishnan2017}.  All
intellectual  ideas  in  this  journal article  are  original  contributions  of
this  thesis  author.  All  text,  tables, figures  and  captions  therein  were
contributed solely by this thesis author. Copyright clearance for non-commercial
verbatim  reproduction  of  the  content  (such as  in  this  thesis)  has  been
secured  through  the  publication  agreement with  the  copyright  holder  ASME
(see \cref{ch:permissions}). The contents in this chapter  may be, in full or in
part, included verbatim from the said publication. This author wishes to express
his  thankfulness  to  Teng  Zhang,  co-author  of  this  journal  article,  for
checking  my  calculations  and  providing  valuable  feedback  that  helped  to
refine  the  manuscript  for  this publication.}.  From  the  literature  review
presented  in \cref{ch:littreview},  it  may  be  recalled  that  transcendental
transfer  functions  of  the  cell's  electrochemical  field  variables  (except
for  concentration   and  potential   in  the   electrolyte)  was   obtained  by
Smith~\etal~\cite{Smith2007} through  linearisation of the  underlying \gls{p2d}
model  equations. Lee~\etal~\cite{Lee2012a,Lee2012}  extended  this approach  to
obtain  the  missing  electrolyte   transfer  functions  through  a  multi-modal
EigenFunction expansion employing a Sturm-Liouville approach~\cite{Pryce1993}.


In  order  to  obtain  a  \gls{lti} state-space  representation  of  the  system
(see \cref{eq:LTIstatespace}) for  embedded implementation,  Lee~\etal{} devised
the   \gls{dra},  a   numerical  procedure   to  systematically   transform  all
transcendental  transfer functions  to  the time  domain.  The \gls{dra}  method
retains  the physical  nature  of  the original  \gls{dfn}  equations until  the
very  last  step  wherein  the  matrices governing  the  system's  dynamics  are
generated. This  yields a  one-dimensional discrete-time  \gls{rom} of  the cell
that is entirely based upon  fundamental physical principles. The \gls{rom} thus
obtained could  then be used to  compute the time-evolution of  all the internal
electrochemical quantities of  the \gls{dfn} model. Prima~facie  it appears that
this  model  could be  directly  implemented  as the  plant  model  for a  state
estimation  application.  However, a  comprehensive  analysis  of the  procedure
reveals certain issues that must  be first tackled before implementation aspects
can be considered.


An unresolved issue of Lee\textquoteright  s reduced-order modelling approach is
the high computation requirement associated with  DRA, which has to be performed
multiple  times to  identify cell  parameters  at various  SOC and  temperatures
(cite  book \&  thesis). This  bottleneck  arises from  the need  to form  large
Block-Hankel matrices of the Markov parameters in memory, which is then suitably
factorized by a Singular Value Decomposition (SVD) step which is computationally
expensive.In this paper, we analyse the  computational bottleneck in the DRA and
propose a significant  improvement to the DRA procedure. In  Section 2, analysis
of a key step in the DRA, ie. the Singular Value Decomposition of a block-Hankel
matrix (for choosing the model order) is performed (bottleneck 1). An analytical
formulation of  the massive computing  requirements (storage and  floating point
operation  counts) for  replicating  the Lee\textquoteright  s  model (cite)  is
given. Redundancies  and inefficiencies in  this step are  enumerated, therefore
deeming  the computational  requirements as  unnecessary. In  Section 3,  a fast
computational approach is  presented that significantly reduces  both the memory
and the  floating-point operation count  of the CPU.  In Section 4,  the results
arrived at by  applying the algorithms of section 2  are summarized and compared
with the  existing DRA  method. Furthermore,  we compare  and contrast  the much
smaller computational requirements of our  proposed method with the existing DRA
code for  modelling the cell behavior.We  conclude by showing that  the existing
Discrete-Time-Realization (DRA) algorithm can be significantly speeded up by our
proposed methodology.

% important to acknowledge Teng here
% \author[tz]{Teng Zhang\fnref{fn2}}
% \ead{t.zhang@imperial.ac.uk}


(Teng: Pls  edit this paragraph,  Im just throwing  in the story)  An unresolved
issue  of  Lee\textquoteright s  reduced-order  model  is the  high  computation
requirement associated  with DRA, which  has to  be performed multiple  times to
identify cell parameters at various SOC  and temperatures (cite book \& thesis).
This  computation  bottleneck primarily  arises  from  the  need to  form  large
block-Hankel matrices of the Markov parameters,  which is then factorized by the
computationally intensive SVD step. The  high computation requirement of the SVD
practically requires  the Markov parameters  for the slow system  dynamics, i.e.
lithium diffusion  in solid particles,  to be truncated which  therefore affects
model accuracy. As  was point out by Plett (cite  book), \textquoteright \dots .
long  impulse response\dots  large Hanekl\dots{}  makes to  SVD intractable\dots
\textquoteright .


In  this  paper,  we  analyse  the computational  bottlenecks  in  the  existing
modelling process  and propose a  significant improvement to the  DRA procedure.
This paper is organized as follows. In Section  2, analysis of a key step in the
DRA, ie. the Singular Value Decomposition of a block-Hankel matrix (for choosing
the model order)  is performed (bottleneck 1). An analytical  formulation of the
massive computing requirements (storage and floating point operation counts) for
replicating  the model  in Dr.  Lee's paper  (cite) is  given. Redundancies  and
inefficiencies in  this step  are enumerated,  therby deeming  the computational
requirements as unnecessary. Furthermore, another computationally demanding step
in the DRA, viz. the linear algebra  operation for the computation of the system
dynamics  matrix A\_hat  is  identified (bottleneck  2). In  Section  3, a  fast
computational approach using powerful algorithms  is presented that slashes down
both the memory and the floating point operation count of the CPU for bottleneck
1. The same code  is elegantly reused to arrive at a  solution for bottleneck 2,
thereby promoting modularity.  In Section 4, the results arrived  at by applying
the algorithms  of section 2  are presented, by  comparing them to  key internal
variables from the existing DRA method. Furthermore, we compare and contrast the
much  smaller  computational  requirements  of  our  proposed  method  with  the
existing DRA  code for modelling  the cell behavior.  We show that  the existing
Discrete-Time-Realization (DRA) algorithm can be significantly speeded up by our
proposed methodology.


% In  this  paper,  we  analyse  the computational  bottlenecks  in  the  existing
% modelling process  and propose a  significant improvement to the  DRA procedure.
% This paper is organized as follows. Our analysis reveals that the Singular Value Decomposition (SVD) of
% the large Block-Hankel matrix of the system\textquoteright s Markov
% parameters is a key inefficient step. In Section  2, analysis of a key step in the
% DRA, ie. the Singular Value Decomposition of a block-Hankel matrix (for choosing
% the model order)  is performed (bottleneck 1). An analytical  formulation of the
% massive computing requirements (storage and floating point operation counts) for
% replicating  the model  in Dr.  Lee's paper  (cite) is  given. Redundancies  and
% inefficiencies in  this step  are enumerated,  therby deeming  the computational
% requirements as unnecessary. Furthermore, another computationally demanding step
% in the DRA, viz. the linear algebra  operation for the computation of the system
% dynamics  matrix A\_hat  is  identified (bottleneck  2). In  Section  3, a  fast
% computational approach using powerful algorithms  is presented that slashes down
% both the memory and the floating point operation count of the CPU for bottleneck
% 1. The same code  is elegantly reused to arrive at a  solution for bottleneck 2,
% thereby promoting modularity.  In Section 4, the results arrived  at by applying
% the algorithms  of section 2  are presented, by  comparing them to  key internal
% variables from the existing DRA method. Furthermore, we compare and contrast the
% much  smaller  computational  requirements  of  our  proposed  method  with  the
% existing DRA  code for modelling the  cell behaviour. We show  that the existing
% Discrete-Time-Realization (DRA) algorithm can be significantly speeded up by our
% proposed methodology.

% A fast computational approach
% is presented that significantly reduces memory usage and CPU operation
% count by bypassing the redundant Block-Hankel matrix formation step.

% An attractive approach was
% proposed by Lee et al~\citep{LeeChemistruckPlett2012} using a technique
% known as Discrete-time-Realization Algorithm (DRA)~\citep{LeeChemistruckPlett2012a}.
% The ROM thus obtained in standard state-space representation can be
% simulated to obtain the evolution of electrochemical variables of
% the standard porous-electrode Li-ion battery model~\citep{DoyleFullerNewman1993,FullerDoyleNewman1994}.
% An unresolved issue of this approach is the high computation requirement
% associated with the DRA, which needs to be repeated multiple times
% for various SOCs and temperatures.

% Comparisons with existing DRA method highlight the significant reduction
% in computation time and memory usage as well as improved modelling
% accuracy of electrochemical quantities afforded by this new method.

% % In  this  paper,  we  analyse  the computational  bottlenecks  in  the  existing
% % modelling process  and propose a  significant improvement to the  DRA procedure.
% % This paper is organized as follows. In Section  2, analysis of a key step in the
% % DRA, ie. the Singular Value Decomposition of a block-Hankel matrix (for choosing
% % the model order)  is performed (bottleneck 1). An analytical  formulation of the
% % massive computing requirements (storage and floating point operation counts) for
% % replicating  the model  in Dr.  Lee's paper  (cite) is  given. Redundancies  and
% % inefficiencies in  this step  are enumerated,  therby deeming  the computational
% % requirements as unnecessary. Furthermore, another computationally demanding step
% % in the DRA, viz. the linear algebra  operation for the computation of the system
% % dynamics  matrix A\_hat  is  identified (bottleneck  2). In  Section  3, a  fast
% % computational approach using powerful algorithms  is presented that slashes down
% % both the memory and the floating point operation count of the CPU for bottleneck
% % 1. The same concept  is elegantly reused to arrive at  a solution for bottleneck
% % 2,  thereby promoting  modularity.  In  Section 4,  the  results  arrived at  by
% % applying the  algorithms of section  2 are presented,  by comparing them  to key
% % internal variables  from the  existing DRA method.  Furthermore, we  compare and
% % contrast the much smaller computational requirements of our proposed method with
% % the existing DRA code for modelling the cell behavior.

% \section{Analysis of the Computational  Bottlenecks of Discrete-Time Realization
% Algorithm (DRA)}
% \input{4/analysis_bottlenecks.tex}


% \section{Analysis of the Computational  Bottlenecks of Discrete-Time Realization
% Algorithm (DRA)}

% The  Reduced  Order  Model  (ROM)  obtained   by  Dr.  Lee  is  based  upon  the
% thermodynamic and kinetic equations of the one-dimensional volume-averaged model
% first  proposed  by Doyle,  Fuller  and  Newman  (cite). The  overall  modelling
% procedure is summarized  in Figure 1. First, the model  equations are linearized
% about an operating point  and closed-form Laplace-domain transcendental transfer
% functions  of  all  the  internal cell  variables(phi\_s,phi\_e,c\_s,c\_e  \&  j
% at  different  cell locations)are  derived  using  the  applied current  to  the
% cell  as input.  The transfer  functions in  (cite) are  summarized in  Appendix
% I.  The  authors  proposed  a novel  Discrete-time-Realization  algorithm  (DRA)
% in  (DRA\_citation)  to transform  these  transcendental  transfer functions  to
% equations  in standard  state-space representation.  The steps  involved in  the
% Discrete-Time Realization  Algorithm (DRA)  is summarized  in the  block diagram
% (Figure 2). At the heart of this method is the classical subspace identification
% method known  as Ho-Kalman algorithm (cite  2 papers) (visualized in  Figure 3).
% A  key  step  in  the  model  order reduction  process  is  the  Singular  Value
% Decomposition  of  the  Block-Hankel  matrix formed  by  the  Markov  parameters
% (unit-pulse responses)  of the battery  transfer functions. In  the illustrative
% example  provided by  Dr. Lee,  there are  28 transfer  functions, with  applied
% current as the input, ie. we have  a Single input Multiple Output System (SIMO),
% the  Markov parameters  of  which is  collected into  a  Block-Hankel matrix  as
% shown  in  Figure x.  Each  Block  element in  the  Hankel  matrix is  a  column
% vector comprising  of the Markov  parameters at every time-step.  Singular Value
% Decomposition (SVD)  is performed on this  Block-Hankel matrix and plotted  as a
% visual aid to provide  an insight into the system order.  A detailed analysis of
% this procedure reveals certain weaknesses,  issuesand inefficiencies in this SVD
% computation step as discusses below.

% \subsection{Size of the Block-Hankel Matrix}

% The SVD computation can become intractable if the Hankel matrix becomes
% very large. For Li-ion battery modelling, this happens due to the
% following.
% \begin{enumerate}
% \item For a desired duration of markov-parameter recording for the SIMO
% system, if the model's sampling frequency is increased, the emulation
% frequency F1 has to be proportionately increased for the interpolation
% in step 3 to be accurate. This requires that the total number of time-samples
% for each Markov parameter (N) to be scaled proportionately to capture
% the duration of the unit-pulse-response. However, the number of entries
% in the Hankel matrix increases as per a quadratic law.
% increases quadratically with N.
% \item The recorded sample size for each Markov parameter, N, could also
% become large if the unit-pulse-response of just one of the transfer
% functions of the SIMO system decays very slowly. In Li-ion batteries,
% diffusion within the solid particle is typically the slowest process.
% In the case of the cell modelled by Lee et al, the Markov parameters
% of the surface concentration of Li adjacent to the positive current
% collector require approximately 8000 (16000) samples before reducing
% to an appreciably low value, as shown in figure x.
% \item For a battery modelling problem consisting of multiple transfer functions
% (28 in this case), the number of entries in the Hankel matrix also
% scales linearly with number of transfer functions. Thus, if more transfer
% functions (say, concentrations and potentials at different locations
% in the cell) need to be modelled, then the size of the Block-Hankel
% matrix increases correspondingly.
% \end{enumerate}
% Combining both the effects above, if x transfer functions are to be
% modelled and N samples of markov parameters are to be captured for
% the duration of interest, the size of the Block-Hankel matrix would
% be
% \[
% Size(H)\sim O(xN^{2})
% \]
%  The size of the Hankel matrix has a significant computational impact
% as described in the following sections.

% \subsubsection{Effect on Computational Demand}
% Considering the above effects combined, if $x$ transfer functions
% are to be modelled and $N$ time-samples of each markov parameter
% are to be captured, the size of the Block-Hankel matrix shall become
% \begin{equation}
% Size(H)\sim O(xN^{2})\label{eq:}
% \end{equation}
%  The large size of the Block-Hankel matrix has a significant computational
% impact as shown in Sections~\ref{sub:Traditional-DRA--Memory} and
% \ref{sub:Traditional-DRA--CPU}.

% If the unit-pulse-response of just any one of the transfer functions
% of the SIMO system does not die down to zero in a reasonable duration,
% the recorded sample size for each Markov parameter, N becomes very
% large. In Li-ion batteries, diffusion within the solid particle is
% considered to be the slowest i.e.rate-determining step. In the case
% of the cell modelled by Dr. Lee, the Markov parameters of the surface
% concentration of Li next to the positive current collector dies out
% very slow as shown in figure x.

% \subsubsection*{Analysis of Memory (RAM) Requirements for computing SVD}

% Dr. Lee chose to use 8000 samples for his reduced order model with
% a sampling interval of 1 second to allow settling of the solid surface
% concentration to an acceptably low magnitude. The size of the Block-Hankel
% matrix thus formed is 224000 x 8000, ie. $1.792x10^{9}$entries. Using double-precision arithmetic
% (4 bytes on most computer architecture), the storage requirement for
% this Block-hankel matrix can be estimated as13.35 GB.

% However, as seen in the unit-pulse-response (earlier figure), the
% Markov parameter does not quite die down to zero.
% diminsh to zero. (Diffusion being a $t^{1/2}$ process, it would require
% an infinite number of poles and zeros to capture this system as highlighted
% in Bode). Thus, for theoretical accuracy, infinite number of samples
% are required.With practical considerations for implementation in a
% digital computer, following IEEE floating point notation, it is only
% need to capture until the samples are within an order of the machine-epsilon.
% Truncating at 16000 (32000) samples would require about 27 GB RAM
% for holding the Block-Hankel matrix.
% Recording the Markov
% parameters till 16000 seconds would require about 27GB RAM for storage.Furthermore,
% after computing the SVD, three more large matrices $U,Vand\Sigma$of
% the same size are formed in memory. Thus, running the algorithm necessitates
% a requirement of 26.68 GB of free memory. For calculating the system
% dynamics matrix A\_hat, the row-shifted Hankel matrix (symbol here)
% is also held in memory (although to be fair, only the first n number
% of columns of U, V and Sigma are retained before this computation,
% and the original unshifted Hankel matrix can be cleared to free up
% RAM) is further compounded by the necessity of more higher frequency
% models. For using the reduced order model successfully in high-dynamic
% load drive-cycles (like cite e.g.), it requires that the model be
% valid at least until the highest operating frequency of the drive-cycle.
% Assuming no computational errors, the sampling frequency required
% to perfectly capture all the dynamics will be at least twice of this
% nyquist frequency. For the UDDS drive-cycle, the highest frequency
% content of the input current is. Thus, if the reduced order model
% (ROM) running at 0.5s (verify) sample time is to be derived, then
% 32000 time-samples are needed for each Markov parameter for capturing
% the pulse duration until 16000 seconds. Analysis of the memory calculation
% yields $4x28x(32000)^{2}$bytes = 114688000000 byes = 106.8 GB of
% free memory for holding the Hankel matrix alone, and a total of 427
% GB of free memory for holding the resulting output matrices. Intermediate
% memory storage during the SVD computation and the baseline operating
% memory are not taken into account in this calculation. The problem
% is further compounded by having a battery model wherein the smaller
% diffusion coefficients are smaller than those studied here. The Markov
% parameters of the solid surface concentration transfer function shall
% now decay to zero further slowly, necessitating a very large number
% of samples to be captured. Furthermore,obtaining the battery model
% at different SOCs and temperature would mean that we need to re-linearize
% the original PDEs under those conditions and obtain the corresponding
% transfer functions, markov parameters and Block-Hankel matrices. These
% large matrices have to be loaded onto the memory for every SOC and
% temperature run, thereby significantly slowing down the modelling
% procedure. This analysis reveals that doubling the number of transfer
% functions doubles the size of the Block-Hankel matrix.


% Edit this - Furthermore, after computing the SVD, three more similar-sized
% matrices $U$,$V$and \textgreek{S} are formed in memory, necessitating
% a requirement of 26.7 GB of free memory - edit this). but the intermediate
% operational memory requirement for SVD is the highest. The in-operando
% memory requirement is the highest. S is n{*}n, U is (2000{*}28{*}10xn),
% V is (28{*}n).


% The memory requirement is further compounded by the necessity of generating
% high sample-rate discrete-time models. For using the reduced order
% model successfully in high-dynamic load drive-cycles (like cite e.g.),
% it requires that the model be valid at-least until the highest operating
% frequency of the drive-cycle. For the UDDS drive-cycle (cite), the
% highest frequency content of the input current is XXX. Thus, if the
% reduced order model running at 0.5s (verify) sample time is to be
% derived, then 32000 samples for each transfer function is needed for
% capturing the unit-pulse response until 16000 seconds. This implies
% that106.8 GB of free memory is needed for holding just the Block-Hankel
% matrix, and a total of 427 GB of free memory is needed for holding
% the resulting output matrices of the SVD. Furthermore, obtaining the
% battery model at different SOCs and temperature would mean the necessity
% to re-linearize the original PDEs under those conditions and obtain
% the corresponding transfer functions, markov parameters and Block-Hankel
% matrices. These large matrices have to be loaded onto the memory for
% every SOC and temperature run, thereby significantly slowing down
% the modelling procedure.

% Considering the above effects combined, if $x$ transfer functions
% are to be modelled and $N$ time-samples of each markov parameter
% are to be captured, the size of the Block-Hankel matrix shall become
% \begin{equation}
% Size(H)\sim O(xN^{2})\label{eq:}
% \end{equation}
%  The large size of the Block-Hankel matrix has a significant computational
% impact as shown in Sections~\ref{sub:Traditional-DRA--Memory} and
% \ref{sub:Traditional-DRA--CPU}.


% \subsubsection{Traditional DRA -Memory (RAM) Requirements\label{sub:Traditional-DRA--Memory}}

% Lee et al used 16000 samples for the ROM workflow with a sampling
% interval of 1 second. This allows sufficient time for the Markov parameters
% of the solid surface concentration to settle to an acceptably low
% magnitude. The size of the Block-Hankel matrix thus formed consists
% of $224000x8000=1.79x10^{9}$ entries. Using double-precision arithmetic,
% the storage requirement for this Block-hankel matrix alone can be
% estimated to be 27 GB.

% However, as seen in Figure~\ref{f:markov_cse_pos}, the Markov parameters
% of the solid surface concentration does not diminsh exactly to zero.
% Diffusion being a $t^{1/2}$process, an infinite number of poles and
% zeros is required to capture the full dynamics of this system. This
% is highlighted by the -10 dB/decade slope of the Bode Magnitude plot
% (Figure~\ref{f:bode}) of the Jacobsen-West transfer function~\citep{JacobsenWest1995}
% describing solid diffusion.Thus, infinite number of Markov parameter
% samples are required to capture the system dynamics accurately. With
% practical considerations for implementation in a digital computer,
% following IEEE floating point notation, it is only need to capture
% the samples until their magnitude is within order of machine-epsilon.

% \begin{figure}[h]
% \input{bode.tex}
% \caption{Solid Diffusion Transfer Function (Positive Electrode)}
% \label{f:bode}
% \end{figure}

% \subsubsection*{Analysis of CPU Operation Count for computing SVD}

% The most widely used numerical algorithm for computing the full Singular
% Value Decomposition (SVD) of a general dense matrix $A\epsilon\mathcal{R}^{mxn},m\geq n$
% is the Golub-Kahan-Reinsch method (cite). The first stage involves
% reducing the dense matrix $A\epsilon\mathcal{R}^{mxn},$into an upper
% bidiagonal matrix $B\epsilon\mathcal{R}^{mxn}$by the standard bidiagonalisation
% algorithm using Householder reflections. This algorithm requires $4mn^{2}-4n^{3}/3$
% operations. However, in the case of battery modelling problem, we
% always have a 'tall' Block-Hankel matrix, since the number of time-samples
% of the unit-pulse response collected is far greater than the number
% of transfer functions being modelled., i.e. $m\gg n$. Furthermore,
% there exists an efficient algorithm for this step if $m\geq5n/3$
% known as $\mathcal{R}$-Bidiagonalisation (cite), which first reduces
% the matrix $A\epsilon\mathcal{R}^{mxn}$ to a triangular matrix using
% the QR\LyXFourPerEmSpace decomposition and then employing Householder
% reflections to further reduce the matrix to bidiagonal form. Again,
% this condition of $m\geq5n/3$ is always satisfied for the Block-Hankel
% matrix formed by the markov parameters of a vector of transfer functions
% of a typical battery. The operation count for the $\mathcal{R}$-Bidiagonalisation
% step is $2mn^{2}+2n^{3}$. The second stage computes the SVD of the
% upper bidiagonal matrix $B\epsilon\mathcal{R}^{mxn}$ using an iterative
% procedure (Demmel-Kahan method) upto a certain precision, typically
% the machine epsilon (cite). The second stage takes $\mathcal{O}(n)$iterations,
% each costing $\mathcal{O}(n)$ floating point operations.This is typically
% done by a variant of the QR\LyXFourPerEmSpace algorithm for the computation
% of eigenvalues, which was first described by Golub\LyXFourPerEmSpace \&\LyXFourPerEmSpace Kahan\LyXFourPerEmSpace (1965).
% The LAPACK subroutine DBDSQR implements this iterative method, with
% some modifications to cover the case where the singular values are
% very small (Demmel\LyXFourPerEmSpace \&\LyXFourPerEmSpace Kahan\LyXFourPerEmSpace 1990).Together
% with a first step using Householder reflections and, if appropriate,
% QR decomposition, this forms the DGESVD routine for the computation
% of the singular value decomposition for a real rectangular matrix.
% Other variants of this routine are available including DGESDD (which
% uses a divide-and-conquer algorithm for the bidiagonal SVD) and ZGESDD
% (for SVD of a complex matrix). The DSESVD algorithm, originally implemented
% in LAPACK is numerically stable and versitile has ported onto many
% numerical computation packages (MATLAB,GNU Octave, Scilab) and numerical
% libraries (NAG, Intel MKL) that this is the de-facto SVD algorithm
% nowadays . The MATLAB implementation svd is also based upon this.

% If $\mathcal{R}$-Bidiagonalisation for stage I of the SVD computation,
% then the overall process is referred to as $\mathcal{R}-SVD.,$which
% is the fastest standard algorithm for the full-SVD computation for
% this battery modelling problem at hand. The exact analysis of the
% overall operation count for computing the singular values and singular
% vectors using the $\mathcal{R}-SVD$ method was analysed in (cite)
% and is shown to be $4m^{2}n+22n^{3}$. For a Block-Hankel matrix constructed
% from the Markov parameters of $x$ transfer functions and $N$ time-samples
% of pulse-response data for each transfer functions, we have $m=xN$
% (rows) and $n=$N (columns)

% \[
% ExactOperationCount=4(xN)^{2}N+22N^{3}=2N^{3}(11+2x^{2})
% \]

% For the battery modelling task at hand, consisting of 28 transfer
% functions, Markov parameters are collected for a duration of 8000
% seconds using a sampling interval of 1second. Thus the operation count
% of SVD is approximately $O(8000^{3})=1.6169e+15floating$point operations.
% On the latest 6th generation Quad-Core Intel Core i7-6700K desktop
% processor (Skylake architecture, 4.2GHz, 8M cache, released August
% 2015) capable of 81.28 GFlops (Whetstone Double-Float Benchmark),
% even with implicit paralleization,this SVD operation procedure would
% theoretically take 1.9893e+04 seconds = 331.5486 minutes = 5.525 hours.
% To obtain the reduced-order battery model for a wide SOCs and temperatures
% we need to re-lineare the original PDE equations for these conditions
% (cite). This implies that the SVD has to be re-computed for the new
% set of . For 20 SOC points from 0 to 100\% and for a temperature range
% from -10C to 40C at increments of 10C, there are a total of 120 operating
% points, which means that 663 hours of operation on a high-end machine.
% The SVD computation time scales up as the cube of the chosen number
% of time-samples of the unit pulse-response, rendering calculations
% for anything more than 8000 samples virtually intractable, which would
% automatically preclude choosing a lower sampling frequency of the
% model and inherently prevents capturing the dynamics of drive-cyles
% above 2Hz (for this specific case under consideration with 1 second
% sampling frequency). Mention about 16-core workstation and estimate
% the hours of SVD operation for a single SOC and temperature. Choosing
% more transfer functions to study has a quadratic increase on the number
% of floating point operations. Thus doubling the number of transfer
% functions being modelled will effectively require about 22 hours on
% the quad-core machine and \_\_\_ hours on the 16-core workstation
% for computing the SVD at a single SOC and temperature. Although a
% GPU farm computation of the SVD using CUDA/OpenCL libraries can be
% considered, large scale data movement quickly overwhelms the GPU pipelines.
% Furthermore, even the latest NVIDIA Tesla high-end scientific computing
% GPUs cannot handle the sheer amount of memory required even for a
% moderately sized problem of 28 battery transfer functions and 8000
% samples.

% From the above discussion, the SVD computation step in the DRA procedure
% can be identified as Bottleneck \#1.


% An even faster methodIf $\mathcal{R}$-Bidiagonalisation is employed
% for stage I of the SVD computation, then the overall process is referred
% to as $\mathcal{R}$\textminus SVD and is the fastest standard algorithm
% for the full-SVD computation for this battery modelling problem. The
% overall operation count for computing the singular values and singular
% vectors using this method was analysed in (cite) and is shown to be
% $4m^{2}n+22n^{3}$. For a Block-Hankel matrix constructed from the
% Markov parameters of $x$ transfer functions and $N$ time-samples
% of pulse-response data for each transfer functions, we have $m=xN$
% (rows) and $n=N$ (columns).
% \begin{alignat*}{2}
% \mathcal{R}-SVD\text{ Operation Count} & = & \,4\left(xN\right){}^{2}N+22N^{3}\\
%  & = & \,2N^{3}\left(11+2x^{2}\right)
% \end{alignat*}

% Thus the CPU operation count scales as $\mathcal{O}(N^{3})$ with
% the number of time-samples and as $\mathcal{O}(x^{2})$ with the number
% of transfer functions being modelled. For the battery model in Lee
% et. al consisting of 28 transfer functions, (Markov parameters collected
% for 8000 (16000) seconds with a 1-second sampling interval), the operation
% count is approximately $\mathcal{O}(8000^{3})=512x10^{9}$ floating
% point operations.

% Note: Mention that SVD can't be easily paralellized, but certain implementations,
% including the MATLAB one can be multithreaded. Check but there is
% a further memory penalty of copying the info to other threads ? Restrict
% Math cluster has only one core. (check specs). Therefore, if multithreading
% is used, computational time may go down , but memory may go yo....need
% to verify all of these thigns.

% \subsubsection{Summary Effect of Computational Bottlenecks}

% Although the analytical framework of the reduced order model formulation
% allows the user to simulate the cell-variables at any location of
% interest, in practice, this capability is severely hampered by the
% bottlenecks in the DRA. The real-life scenarios enumerated below highlights
% the significant reduction in the general applicability of this modelling
% approach..

% The foregoing analysis clearly demonstrates that the memory and CPU
% requirements in computing the SVD step of the DRA severely hamper
% the scope and applicability of the ROM based on the current DRA algorithm.
% The large memory requirement associated with the bock Hankel matrix,
% in particular, also means that the model identification process is
% not accessible to a large number of research groups without specialized
% computing infrastructure. The computation bottleneck becomes particularly
% limiting in studying the following real-life scenarios:
% \begin{enumerate}
% \item The linear increase in memory requirement with the number of transfer
% functions quickly limits the number of transfer functions can be studied,
% e.g. Studying cell-variables at other locations, that may be of interest
% within the cell, e.g. in the middle of the electrode thicknesses becomes
% intractable.
% \item The quadratic increase in the SVD operation count with the number
% of transfer functions greatly reduces the computational speed. This
% inhibits a quick 'what-if' scenario analysis, e.g. monte-carlo sweep
% to understand the effect of just physical parameter like the diffusion
% coefficient or conductivity would require the user to wait for hours
% on-end at the terminal, defeating the end gains of the model order
% reduction process
% \item The extensibility of the model will significantly slow down in studying
% battery systems of lower diffusivity, e.g. in the case of Li-S batteries,
% the precipitation step is the rate-limiting step and the Markov parameters
% die down after a very long duration. This necessitates early truncation
% of the Markov parameters to avoid computing bottlenecks and hence,
% resulting in severe modelling errors (due to errors in the singular
% values and vectors)
% \item Cell-variables at other locations locations of interest within the
% cell (e.g. in the middle of the electrodes or separator) might need
% to be modelled in the system in addition to the 28 cell variables
% studied in Lee et al. The increased number of cell variables correspond
% to increased number of transfer functions, which in turn require a
% linear increase in memory and quadratic increase in CPU usage.
% \item Battery systems consist of systems with a mix of slow and fast internal
% dynamics. The slow internal dynamics, e.g. solid phase diffusion in
% Li-ion and precipitation in Li-S cells, whose Markov parameters decay
% after a very long duration become a limiting factor in deriving the
% model due to excessive increase in computing requirement. This necessitates
% early truncation of the Markov parameters to avoid computing bottlenecks
% and hence, resulting in modelling errors (due to errors in the singular
% values and vectors computed)
% \item High-frequency load cycles (like the NEDC? which has higher dynamics
% than the UDDS results shown in Lee et. al), which necessites a correspondinly
% higher sampling frequency and hence a larger $N$. cannot be studied
% at all.
% \item In a battery model with a different set of physical parameters (larger
% particle radius, slower solid-diffusion coefficient) than that studied
% in Lee et al, even the achieved accuracy levels might not be repeatable,
% yielding the universal applicability of the DRA process questionable.
% \end{enumerate}
% The large memory requirement also means that the modelling process
% is not accessible to a large number of research groups without specialized
% high-memory computing infrastructure. Even with access to a computing
% machine with high memory and powerful processor, the modelling process
% takes hours of computation for a single SOC and temperature.Repeating
% the process across various SOCs and temperatures would naturally slow
% down the whole modelling procedure, thus defeating the larger goal
% of the reduced order modelling process.
% Even with access to a computing machine with high memory and powerful
% processor, the modelling process takes hours of computation for a
% single SOC and temperature.Repeating the process across various SOCs
% and temperatures would naturally slow down the whole modelling procedure,
% thus defeating the larger goal of the reduced order modelling process.

% \section{Efficient Computation of Block-Hankel SVD}

% Apart from circumventing the computing infrastructure requirement,
% research into efficient SVD implementation is motivated by the following
% scientific rationale.
% The computational bottleneck presented here is recognized in (cite)
% and the use of the Eigen Realization Algorithm (ERA) was proposed
% as a means to partially mitigate the issue. which allows for a moderate
% reduction in memory requirements and CPU floating-point operations.
% This is done by intentionally omitting a few of the Markov parameters,
% and hence deleting some of the rows and columns of the Block-Hankel
% matrix, thereby reducing its size. Furthermore, the ERA algorithm
% is typically intended for system identification in the case of noisy
% measured data. However, for a battery modelling problem, the Markov
% parameters are obtained from noise-free analytical transfer functiions.
% Thus, there is no clear direction in the form of a published rigorous
% method for selection of the rows and columns to be omitted.

% Apart from needing computing infrastructure with a large memory to
% handle the block-Hankel matrices and high-end processors to handle
% the traditional full-SVD routine, research into efficient SVD implementation
% is motivated by the following scientific rationale.
% \begin{enumerate}
% \item Markov parameters of most battery transfer functions settle to their
% final steady-state fairly quickly. Thus, it is inefficient to record
% the Markov parameters of these transfer functions as entries of the
% Block-Hankel matrix thereby increasing its size. However, in the current
% modelling architecture, in order to account for a few slow dynamics
% (particularly the solid surface concentration), the markov parameters
% of the entire SIMO vector of all transfer functions is fed into the
% Block-Hankel matrix. This degrades the performance, especially since
% accumulating more time-samples heavily influences memory requirement
% in forming the Block-Hankel matrix and the operation count in computing
% the SVD.
% \item The Block-Hankel matrix, whose entries are simply the Markov parameters
% arranged in a special way is essentially redundant information. Thus,
% in theory, it is wasteful to construct this huge matrix especially
% given the fact this is the primary bottleneck for the SVD. If the
% SVD operation can be performed on a virtual Hankel matrix, the memory
% requirements can be drastically reduced.
% \item The matrix of singular values,$\Sigma$ is diagonal and thus, highly
% sparse. After the full SVD (of a Hankel matrix with 8000 time-samples
% and 28 data points), a 6 GB matrix of mostly zeros is constructed
% in memory. Clearly, this is redundant.
% \item Furthermore, performing a full SVD operation is not required for model
% reduction. The transfer functions forming the battery model yield
% a large number of poles with a mix of fast and slow dynamics. The
% idea behind SVD computation is to reduce the order of the system and
% obtain a low-order approximation. Hence, it is sufficient to compute
% a truncated SVD yielding the first few significant values (i.e. an
% upper-bound of desired system order decided a~priori).
% \item Markov parameters of most battery transfer functions (other than the
% rate-limiting step, i.e. Li-diffion in solid particle) settle to their
% final steady-state fairly quickly. Thus, it is inefficient to record
% the Markov parameters of the entire SIMO system for the entire duration
% needed to capture the slowest dynamics. the entire SIMO vector of
% all transfer functions is fed into the Block-Hankel matrix. This degrades
% the performance as accumulating more time-samples increases the size
% of the Block-Hankel matrix leading to the memory and CPU bottlenecks
% for SVD computation step as discussed in Section \ref{subsec:Effect-on-Computational-Demand}
% \item The Block-Hankel matrix, whose entries are nothing but the Markov
% parameters arranged in a repeating special structure is essentially
% redundant information. Thus, in theory, it is wasteful to construct
% this huge matrix especially given that this is the primary bottleneck
% for the SVD. If the SVD operation can be performed on a virtual Hankel
% matrix, the memory requirements can be drastically reduced.
% \item The matrix of singular values,$\,\Sigma$ is diagonal and thus, highly
% sparse. After the full SVD (of a Hankel matrix with 8000 (16000) time-samples
% and 28 data points), a 6 GB matrix of mostly zeros is constructed
% in memory. Clearly, this is redundant information.
% \item Performing a \textit{full} SVD operation is not required for model
% order reduction. The transfer functions forming the battery model
% yield a large number of poles with a mix of fast and slow dynamics.
% The idea behind SVD computation is to reduce the order of the system
% and obtain a low-order approximation. Hence, it is sufficient to compute
% a truncated SVD yielding the first few significant values (i.e. an
% upper-bound of desired system order decided a~priori).
% \end{enumerate}
% Having identified the formulation of the Block-Hankel matrix as the
% origin of the computational bottleneck, we propose an improved method
% of computing this specific SVD that retains the powerful physics-based
% reduced order modelling based, but replacing the key bottlenecks in
% the DRA with highly efficient computational algorithms.

% \subsection{Fast, reduced-Memory SVD Implementation for Battery Modelling}

% The DGESVD algorithm mentioned in Section 2, originally implemented
% in LAPACK is a numerically stable and versitile algorithm for computing
% SVD of a generic real rectangular matrix. This routine has been ported
% onto many numerical computation packages (MATLAB,GNU Octave, Scilab)
% and numerical libraries (NAG, Intel MKL) that this is the de-facto
% SVD algorithm nowadays, and the MATLAB implementation svd is also
% based upon this code. However, owing to its inherent generality, this
% SVD routine does not take advantage of the special anti-diagonal symmetry
% structure of the Block Hankel matrix arising in this battery modelling
% problem. As mentioned in Section 2, computing the full-SVD is wasteful
% in a reduced order modelling application given that only the first
% few leading triplets are intended to be used. Hence, for obtainig
% a reduced order model, it is desirable to impose an a~priori upper
% bound of a system order. Thus, the candidate SVD algorithm needs to
% compute only the first few leading eigen triplets (Singular values
% and corresponding singular vectors), upto the chosen system order.
% Thus iterative algorithms like the Jacobi and Lanczos schemes described
% in {[}45{]} can be considered for computation of the dominant singular
% values of a Block-Hankel matrix. To keep the computation accessible
% to the large community of battery researchers and to encourage widespread
% adoption of the fast reduced order modelling, we consider only open-source
% libraries available for free in the public domain. Otherwise the gains
% brought about by efficient computation of SVD (i.e. using more affordable
% computer hardware) would be offset by comercial licensing terms, usage
% restrictions and other monetary drawbacks of using proprietary codes.
% The Jacobi scheme is available in the free open-source package LAPACK
% via the xGESVD routine. The implicitly restarted Lancsoz scheme is
% available in the ARPACK libraries (which are in Fortran 77). The 'economy'
% size SVD implementation in MATLAB (i.e. the svds function)also implements
% ARPACK.

% The main drawback of both these specific implementations are that
% their input argument is the matrix itself whose SVD needs to be computed.
% For reasons detailed in Section 2, the chosen SVD algorithm must be
% able to handle the computation without actually forming the huge block-Hankel
% matrix in memory. The pioneering work of Rasmunk Munk Larsson, PROPACK,
% designed specially for large and sparse matrices, implemented a numericallty
% stable and Lanczos SVD computation that could accept its input arguments
% in the functional form rather than as matrices. The functional inputs
% needed are multiplication routines for the Hankel matrix and its transpose
% with an arbitrary vector. The PROPACK code is distributed under a
% permissive BSD license. Furthermore, the PROPACK implementation of
% Lancsoz is available as both Fortran 77 and MATLAB codes thereby widening
% its reach. Finally, the PROPACK package includes special algorithms
% to compensate for the numerical errors introduced in the Lanczos bidiagonalisation
% and ensures orthogonality of the input and output singular vectors
% by using Gram-Schmidt partial reorthogonalization scheme.

% In order to use the salient feature of PROPACK, i.e. the flexibility
% to supply it with a functional form of the matrix-vector multiplication
% routines, the key is to use an algorithm that effectively exploits
% the affine structure of the block Hankel matrix without actually forming
% it in memory. Recent research conducted in a specialized time-series
% analysis method known as Singular Spectrum Analysis (SSA) has yielded
% efficient methods for achieving this goal. Korobeynikov (cite) proposed
% an algorithm that uses the Fast Fourier Transform (FFT) for this matrix-vector
% product by embedding the Markov parameters into the column vectors
% of a circulant matrix. This is suitable for applications wherein the
% Hankel matrix is composed of scalar entries formed by the Markov parameters
% of a single input single output (SISO) transfer functon. Golyandina
% and Usevich (cite) extended this to a generic 2D-case for performing
% Singular Spectrum Analysis (SSA) on images, which is capable of handling
% Block-Hankel matrices such as the ones formed by a Multi-Input-Multi-Output
% (MIMO) system. Instead of forming the huge Block-Hankel matrix, the
% algorithm works directly on the much-smaller matrix of Markov-parameters,
% with rows corresponding to the battery transfer functions being modelled
% and the columns corresponding to the total number of time-samples
% recorded. Discuss the operational count here. Discuss the memory requirements
% here.

% The Golyandina-Usevich algorithm along with specific considerations
% to the battery modelling problem is briefly summarised in Appendix
% xx. The algorithm offers several advantages like pre-computation of
% fast-fourier-transform of the Markov Parameter Matrix (MPM), and efficient
% code reuse for computation of the matrix-vector product for both the
% Hankel matrix and its transpose. Thus, the strategy is to use the
% Golyandina-Usevich algorithm for the matrix-vector multiplication
% routines and feeding them as inputs to the PROPACK codes without forming
% the huge matrices in memory. The results discussed in Section \ref{sec:Results}
% demonstrate the performance improvement using these routines without
% any trade-off in fidelity of the model. In fact, the Reduced Order
% Model's accuracy can be improved since the need for early truncation
% of the Markov parameters is virtually eliminiated since there is no
% need to form the Block-Hankel matrix anymore in memory. MATLAB codes
% for the proposed workflow are made available as supplementary material
% for download.

% \subsection{Analysis of CPU Operation Count}

% \subsection{Analysis of Memory Requirements}

% \section{Simulation and Results\label{sec:Results} }

% In this section, we demonstrate the performance improvement, viz.
% improved accuracy as well as reduced computational requirements of
% the modified DRA algorithm by comparing it against the original algorithm
% in Lee et al. The numerical accuracy of both the original and improved
% DRA in predicting the cell's internal variables is compared against
% the full-order pseudo-2D porous-electrode PDE model simulated using
% COMSOL Multiphysics 5.1. The cell parameters are those published by
% Doyle et al. and listed in \ref{sec:Table-of-Battery}. The specifications
% of the computer workstation used in these simulation is shown in Table
% xx. All simulation parameters are listed in Table xx and is the same
% as that reported in Lee et al. .

% \begin{table}

% \caption{Simulation Parameters}

% \begin{tabular}{|l|c|}
% \hline
% Initial Cell SOC & 60\%\tabularnewline
% \hline
% \hline
% Hankel Block Size & 8000\tabularnewline
% \hline
% Sample-Time of Discrete-Time model, $T_{s}$ & 1 sec\tabularnewline
% \hline
% Number of Electrolyte EigenModes & 5\tabularnewline
% \hline
% Emulation (Interpolation) Frequency, $F_{1}$ & 128 Hz\tabularnewline
% \hline
% Desired Number of Singular Values & 10\tabularnewline
% \hline
% \end{tabular}

% \end{table}

% For the first set of simulations, the cell input current is based
% on the US Environmental Protection Agency's (EPA) Urban Dynamometer
% Drive Schedule (UDDS) is shown in Figure xx. The maximum frequency
% content in this input current cycle is as shown by the frequency spectrum
% in Fig xx.

% To highlight the increased computational requirements and reduced
% accuracy of the original DRA under highly-dynamic loads, the NEDC/Hwy/Other
% Suitable drive cycles. The spectrum reveals that the highest frequency
% content is xx.

% \begin{figure}[tbp]
% \input{markov_cse_pos_zero.tex}
% \caption{Time Evolution of Markov Parameters}
% \label{f:diagram}
% \end{figure}

% \begin{figure}[!ht]
% \centering
% \includegraphics{block_Hankel_structure.png}
% \caption{Write some caption here}
% \label{random}
% \end{figure}

% Rough ideas and words...need to edit.

% Existing algorithm also uses \texttt{svds}. ``Error using svd Requested
% 224000x224000 (373.8GB) array exceeds maximum array size preference.
% Creation of arrays greater than this limit may take a long time and
% cause MATLAB to become unresponsive.''
% .The numerical accuracy of both the original and improved DRA in predicting
% the cell's internal variables is compared against the full-order pseudo-2D
% porous-electrode PDE model simulated using COMSOL Multiphysics 5.1.

% For the first set of simulations, the cell input current is based
% on the US Environmental Protection Agency's (EPA) Urban Dynamometer
% Drive Schedule (UDDS).


% This leads to the possibility of modelling other electrochemical quantities
% in the cell geometry without being hindered by memory limitations.
% Furthermore, high sample-rate models to handle highly dynamic load
% profiles can be deployed in future BMS applications. This also empowers
% the ROM framework to tackle cells with slower dynamics or perhaps
% chemistries with slowe rate-limiting reaction mechanisms.

% Is of value in very large system, and the iterative cost of computing
% the Lamncoz becomes valuable only when the matrix is above a certain
% size. The size-trade-off on a machine with certain amount of RAM/CPU
% time is also given. The real value is to reduce RMS cell voltage error
% as well as error in other internal variables. As a typical case, we
% can 1000 operating conditions (soc \& temp) in about 6 hours. Can
% study other areas as well. - not just electrode/separator quickly
% and easily without waiting for the modelling process. SVD was multithreaded.
% (+/-250 MB accuracy for Hankel matrix for 8000 Block-Size, +/-25MB
% for 7000 Block-Size, +/-22.6MB for 6000,+/-22MB for 5000, etc. ).
% Need to get hardware info (esp. CPU info( from par20, large240 and
% large500 queues.). Note: Markov computation can only be performed
% in power of 2\textasciicircum n samples (because of fft calc efficiency).
% The values shown ate interpolated between calc. times (also highly
% dependent on the specific cell parameter values, no. of EigenModes
% chosen etc...Not deterministic ???. In-memory computational RAM for
% the way I am currently computing the Markov parameters, because eval
% function is very very slow, perhaps it might make sense to compute
% only Markov , and keep Hd evaluation separately as off-topic ...Note,
% in the table below, Markov computation includes intermediate storage
% for hd (anyway, regular storage for Hd has to be accounted and added
% up for total memory requirements ?) ??...also think about what to
% do when you show different diffusion rates). Our compiled SVD code
% run as a mex function could potentially be faster. The RAM consumed
% by the new SVD mainly depends on moving data around and passsing it
% between subfunctions in PROPACK etc. Communication overhead. Also,
% fft is memory efficient and faster on certain block-sizes etc. Computed
% mem results for lansvd include circulant fft + lansvd and associated
% subcalls + memory occupied by U, Sigma and V. Computation of Markov
% parameters, time and memory is highly dependent on the emulation (multiplier)
% frequency chosen. Of course, you can optimise a lot with respect to
% sampling freq/emulation freq, truncatiion of Markov etc. ,,, but the
% point is not that...the point is to do a direct comparison of old
% and new methods for same set of parameetsr (for a given set) ;.....and
% removal of a big bottleneck....In the current implementation, the
% mem limit is imposed by no. of electrolyte eigenmodes...the problem
% is really complicated...for high freq model , you need more eigenmodes,
% which means more RAM usage.........not a lot in comparison...but still
% .....Have to check if the same applies if I do MEX thing....Without
% mex, initially limied by Markov, and then quickly becomes limited
% by no. of eigenmodes for memory. MEX is verified to be much much better
% for memory, but double the processing time due to communication overhead.....still
% in seconds

% \begin{table*}
% \begin{tabular}{|>{\raggedleft}m{1cm}|>{\raggedleft}m{1cm}>{\raggedleft}m{1.6cm}rr>{\raggedleft}m{1.6cm}>{\raggedleft}m{1.6cm}>{\raggedleft}m{1.6cm}|}
% \hline
% \multirow{2}{1cm}{Block Size } & \multicolumn{4}{c}{RAM Usage (MB)} & \multicolumn{3}{c|}{CPU Time (sec)}\tabularnewline
% \cline{2-8}
%  & Compute Markov & Hankel Formation & SVD & \multicolumn{1}{r|}{Total} & Hankel Formation & SVD & Total for DRA portion\tabularnewline
% \hline
% 500 & 0.21 & 53.41 & 265.10 & 318.72 & 0.029 & 27.78 & 27.81\tabularnewline
% 1000 & 0.43 & 213.62 & 1107.71 & 1321.76 & 0.11 & 48.33 & 48.44\tabularnewline
% 2000 & 0.85 & 854.49 & 6092.96 & 6948.30 & 0.45 & 131.18 & 131.63\tabularnewline
% 3000 & 1.28 & 1922.60 & 13774.04 & 15697.92 & 1.01 & 407.39 & 408.40\tabularnewline
% 4000 & 1.71 & 3418.00 & 24590.48 & 28010.19 & 2.26 & 640.62 & 642.88\tabularnewline
% 5000 & 2.14 & 5340.60 & 38668.11 & 44010.85 & 3.51 & 908.12 & 911.63\tabularnewline
% 6000 & 2.56 & 7690.40 & 56695.77 & 64388.73 & 5.11 & 1118.42 & 1123.53\tabularnewline
% 7000 & 2.99 & 10468.00 & 77267.02 & 87738.01 & 6.86 & 1918.06 & 1924.92\tabularnewline
% 8000 & 3.42 & 13672.00 & 100282.13 & 113957.55 & 9.59 & 1899.67 & 1909.26\tabularnewline
% 9000 & 3.85 & 17303.00 &  &  & 11.48 & 2876.86 & 2888.34\tabularnewline
% 10000 & 4.27 & 21362.30 &  &  & 14.30 & 3781.26 & 3795.56\tabularnewline
% 11000 & 4.70 & 25848.39 &  &  & 17.35 & 5224.82 & 5242.17\tabularnewline
% 12000 & 5.13 & 30761.72 &  &  & 21.62 & 5561.09 & 5582.71\tabularnewline
% 13000 & 5.55 & 36102.29 &  &  & 24.20 & 5728.16 & 5752.36\tabularnewline
% 14000 & 5.98 & 41870.12 &  &  & 28.55 & 6692.76 & 6721.31\tabularnewline
% 15000 & 6.41 & 48065.19 &  &  & 33.41 & 6467.43 & 6500.84\tabularnewline
% 16000 & 6.84 & 54687.50 &  &  & 38.71 & 9963.52 & 10002.23\tabularnewline
% \hline
% \end{tabular}

% \caption{Computational Requirements of Traditional DRA}
% \end{table*}

% \begin{table}
% \begin{tabular}{|>{\raggedleft}m{1cm}>{\raggedleft}m{1.5cm}>{\raggedleft}m{1cm}>{\raggedleft}m{1cm}c|}
% \hline
% \multirow{2}{1cm}{Block Size} & \multicolumn{2}{c}{RAM Usage (MB)} &  & \multirow{2}{*}{CPU Time (sec)}\tabularnewline
% \cline{2-4}
%  & Hd+Markov Computation & Markov Only & SVD & \tabularnewline
% \hline
% 500 & 218.13 & 0.21 & Too many & \tabularnewline
% 1000 &        471.53 & 0.43 & to & \tabularnewline
% 2000 &        978.32 & 0.85 & fit in & \tabularnewline
% 3000 &        1485.10 & 1.28 & this table & \tabularnewline
% 4000 &        1991.90 & 1.71 &  & \tabularnewline
% 5000 &        2498.70 & 2.14 &  & \tabularnewline
% 6000 &        3005.50 & 2.56 &  & \tabularnewline
% 7000 &        3512.30 & 2.99 &  & \tabularnewline
% 8000 &         4019.00 & 3.42 &  & \tabularnewline
% 9000 &        4525.80 & 3.85 &  & \tabularnewline
% 10000 &        5032.60 & 4.27 &  & \tabularnewline
% 11000 &        5539.40 & 4.70 &  & \tabularnewline
% 12000 &        6046.20 & 5.13 &  & \tabularnewline
% 13000 &          6553.00 & 5.55 &  & \tabularnewline
% 14000 &        7059.80 & 5.98 &  & \tabularnewline
% 15000 &        7566.60 & 6.41 &  & \tabularnewline
% 16000 &     8580.10 & 6.84 &  & \tabularnewline
% \hline
% \end{tabular}

% \caption{}

% \end{table}

% \begin{figure}
% \centering
% \input{old_dra_svd_ram.tex}
% \caption{Memory Usage of Existing DRA Method}
% \label{f:2}
% \end{figure}

% \begin{figure}
% \centering
% \input{svd_compare.tex}
% \caption{Note that the first singular value from Plett's paper is diff}
% \label{f:3}
% \end{figure}

% For accuracy comparison and trunction, please plot comparison plots
% of the following longer truncation vs. early trunction

% 1. Time-domain voltage

% 2. all other electrochemical variables

% Please explain the slowest decaying Markov parameter and plot i the
% residue by zooming in. (maybe 4 plots ?)

% \section{Nomenclature}

% \section{References}

% \appendix

% \section{Table of Battery Parameters\label{sec:Table-of-Battery} }

% \section{Golyandina-Usevich Algorithm}

% \section{Basic Lanczos Scheme}

% \section{Symbolic Transfer Functions Modelled}

% \section{Specifications of Workstation Used\label{sec:Specifications-of-Workstation}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% in the end finish with circular look-up table issue that forbids further
